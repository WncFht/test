<!DOCTYPE html>
<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="wnc" name="author"/>
<link href="https://WncFht.github.io/test/graph/Written%20Memories_notes/" rel="canonical"/>
<link href="../Untitled/" rel="prev"/>
<link href="../activity%20watch/" rel="next"/>
<link href="../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.5.47" name="generator"/>
<title>Written Memories_notes - wnc 的咖啡馆</title>
<link href="../../assets/stylesheets/main.6f8fc17f.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet"/>
<link href="https://cdn.tonycrane.cc/jbmono/jetbrainsmono.css" rel="stylesheet"/>
<link href="https://cdn.tonycrane.cc/lxgw/lxgwscreen.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/tasklist.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/flink.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="indigo" data-md-color-primary="blue-grey" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#1">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="wnc 的咖啡馆" class="md-header__button md-logo" data-md-component="logo" href="../.." title="wnc 的咖啡馆">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            wnc 的咖啡馆
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Written Memories_notes
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="切换至夜间模式" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="blue-grey" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="切换至夜间模式">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="切换至日间模式" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="切换至日间模式">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/WncFht/test/" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</div>
<div class="md-source__repository">
    wnc's café
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../index.md">
          
  
    
  
  Home

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Obsidian/aaaa/">
          
  
    
  
  Obsidian 的笔记

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../AI/">
          
  
    
  
  网络

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="wnc 的咖啡馆" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="wnc 的咖啡馆">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</a>
    wnc 的咖啡馆
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/WncFht/test/" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</div>
<div class="md-source__repository">
    wnc's café
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
<span class="md-ellipsis">
    Home
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_1_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
            Home
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../index.md">
<span class="md-ellipsis">
    None
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-ellipsis">
    Obsidian 的笔记
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            Obsidian 的笔记
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Obsidian/aaaa/">
<span class="md-ellipsis">
    aaaa
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Obsidian/test/">
<span class="md-ellipsis">
    test
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    网络
  </span>
</a>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            网络
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../AI/">
<span class="md-ellipsis">
    AI
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../AI%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/">
<span class="md-ellipsis">
    AI学习路径
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Algorithm/">
<span class="md-ellipsis">
    Algorithm
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../CS231n%20Assignment1/">
<span class="md-ellipsis">
    CS231n Assignment1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../CS%E7%B1%BB%E5%A4%A7%E4%B8%80%E8%BF%9B%E7%BB%84/">
<span class="md-ellipsis">
    CS类大一进组
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Compile%20Database/">
<span class="md-ellipsis">
    Compile Database
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Computer%20Advance/">
<span class="md-ellipsis">
    Computer Advance
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Computer%20Basic/">
<span class="md-ellipsis">
    Computer Basic
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Computer%20Science/">
<span class="md-ellipsis">
    Computer Science
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Cortex-A76%E7%BA%A7%E5%A4%84%E7%90%86%E5%99%A8%E8%AE%BE%E8%AE%A1%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/">
<span class="md-ellipsis">
    Cortex-A76级处理器设计学习计划
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Environment%2C%20software%2C%20tools/">
<span class="md-ellipsis">
    Environment, software, tools
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Image%20Classification-Data-driven%20Approach%2C%20k-Nearest%20Neighbor%2C%20train_val_test%20splits/">
<span class="md-ellipsis">
    Image Classification-Data-driven Approach, k-Nearest Neighbor, train_val_test splits
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Language/">
<span class="md-ellipsis">
    Language
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Linear%20classification-Support%20Vector%20Machine%2C%20Softmax/">
<span class="md-ellipsis">
    Linear classification-Support Vector Machine, Softmax
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Makeflie/">
<span class="md-ellipsis">
    Makeflie
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Matlab/">
<span class="md-ellipsis">
    Matlab
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../My_README_on_GitHub/">
<span class="md-ellipsis">
    My_README_on_GitHub
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Optimization-Stochastic%20Gradient%20Descent/">
<span class="md-ellipsis">
    Optimization-Stochastic Gradient Descent
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Python%20Numpy/">
<span class="md-ellipsis">
    Python Numpy
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../ROS2-%E8%B8%A9%E5%9D%91/">
<span class="md-ellipsis">
    ROS2-踩坑
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Robot-control%20theory/">
<span class="md-ellipsis">
    Robot-control theory
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Robot-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/">
<span class="md-ellipsis">
    Robot-参考资料
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Robot-%E6%9C%BA%E6%A2%B0/">
<span class="md-ellipsis">
    Robot-机械
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Robot-%E7%A1%AC%E4%BB%B6/">
<span class="md-ellipsis">
    Robot-硬件
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Robot-%E8%A7%86%E8%A7%89/">
<span class="md-ellipsis">
    Robot-视觉
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SSH/">
<span class="md-ellipsis">
    SSH
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SVM1/">
<span class="md-ellipsis">
    SVM1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../SVM2/">
<span class="md-ellipsis">
    SVM2
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../TCS/">
<span class="md-ellipsis">
    TCS
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Tabby%20%2B%20Zsh/">
<span class="md-ellipsis">
    Tabby + Zsh
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Technology/">
<span class="md-ellipsis">
    Technology
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../UPC%E6%A8%A1%E6%8B%9F/">
<span class="md-ellipsis">
    UPC模拟
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../UPC%E7%9B%B8%E5%85%B3%E7%9A%84%E8%B5%84%E6%96%99/">
<span class="md-ellipsis">
    UPC相关的资料
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Untitled%201/">
<span class="md-ellipsis">
    Untitled 1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Untitled%202/">
<span class="md-ellipsis">
    Untitled 2
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Untitled%203/">
<span class="md-ellipsis">
    Untitled 3
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Untitled/">
<span class="md-ellipsis">
    Untitled
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Written Memories_notes
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Written Memories_notes
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#1">
<span class="md-ellipsis">
      先决条件1
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
<span class="md-ellipsis">
      循环神经网络
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rnns">
<span class="md-ellipsis">
      RNNs能做什么；选择时间步长
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rnn">
<span class="md-ellipsis">
      普通的RNN
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../activity%20watch/">
<span class="md-ellipsis">
    activity watch
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../answer%204/">
<span class="md-ellipsis">
    answer 4
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../attacklab/">
<span class="md-ellipsis">
    attacklab
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../blog/">
<span class="md-ellipsis">
    blog
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../bomblab/">
<span class="md-ellipsis">
    bomblab
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../books%20list/">
<span class="md-ellipsis">
    books list
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../cachelab/">
<span class="md-ellipsis">
    cachelab
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../cgdb/">
<span class="md-ellipsis">
    cgdb
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chezmoi/">
<span class="md-ellipsis">
    chezmoi
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../critical%20respoense%20essay/">
<span class="md-ellipsis">
    critical respoense essay
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../cs231n/">
<span class="md-ellipsis">
    cs231n
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../csapp-lab%E8%AE%B0%E5%BD%95/">
<span class="md-ellipsis">
    csapp-lab记录
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../demo1/">
<span class="md-ellipsis">
    demo1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../demo2.1/">
<span class="md-ellipsis">
    demo2.1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../demo2/">
<span class="md-ellipsis">
    demo2
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../demo3.1/">
<span class="md-ellipsis">
    demo3.1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../demo3/">
<span class="md-ellipsis">
    demo3
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../forum%2C%20website/">
<span class="md-ellipsis">
    forum, website
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../git/">
<span class="md-ellipsis">
    git
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../github%20Action/">
<span class="md-ellipsis">
    github Action
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../graphics/">
<span class="md-ellipsis">
    graphics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../high-quality%20blog/">
<span class="md-ellipsis">
    high-quality blog
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../linux/">
<span class="md-ellipsis">
    linux
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../mkdocs%20material%20github-pages%20%E9%85%8D%E7%BD%AE/">
<span class="md-ellipsis">
    mkdocs material github-pages 配置
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../mkdocs%20material%20github-pages%20%E9%85%8D%E7%BD%AE%E7%9B%AE%E5%BD%95/">
<span class="md-ellipsis">
    mkdocs material github-pages 配置目录
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../mkdocs%20material/">
<span class="md-ellipsis">
    mkdocs material
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../model%201%20on%201106/">
<span class="md-ellipsis">
    model 1 on 1106
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../more%20about%20Machine%20Learing/">
<span class="md-ellipsis">
    more about Machine Learing
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../neovim/">
<span class="md-ellipsis">
    neovim
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../nihao/">
<span class="md-ellipsis">
    nihao
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../obsidian/">
<span class="md-ellipsis">
    obsidian
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../prompt%20for%20GPT/">
<span class="md-ellipsis">
    prompt for GPT
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../rectuitment/">
<span class="md-ellipsis">
    rectuitment
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../remote/">
<span class="md-ellipsis">
    remote
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../reveal-md%20%E6%8C%87%E5%8D%97/">
<span class="md-ellipsis">
    reveal-md 指南
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../route/">
<span class="md-ellipsis">
    route
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../tabby/">
<span class="md-ellipsis">
    tabby
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../test1/">
<span class="md-ellipsis">
    test1
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../test12/">
<span class="md-ellipsis">
    test12
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../test123/">
<span class="md-ellipsis">
    test123
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../typst/">
<span class="md-ellipsis">
    typst
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../vim%20%E5%A4%8D%E5%88%B6%E9%97%AE%E9%A2%98/">
<span class="md-ellipsis">
    vim 复制问题
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../vim/">
<span class="md-ellipsis">
    vim
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F%E7%9A%84%20blog/">
<span class="md-ellipsis">
    一些乱七八糟的 blog
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4%20Ubuntu/">
<span class="md-ellipsis">
    一些命令 Ubuntu
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E5%AD%98%E6%A1%A3%E7%9A%84%E4%BB%A3%E7%A0%81/">
<span class="md-ellipsis">
    一些存档的代码
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E5%AF%86%E9%99%A2%E5%B0%B1%E4%B8%9A%E7%9A%84%E7%BB%8F%E9%AA%8C/">
<span class="md-ellipsis">
    一些密院就业的经验
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93/">
<span class="md-ellipsis">
    一些总结
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8E%86/">
<span class="md-ellipsis">
    一些简历
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E7%BB%93%E6%9E%9C%20%E6%A8%A1%E5%9E%8B/">
<span class="md-ellipsis">
    一些结果 模型
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%80%E4%BA%9B%E9%87%8D%E8%A6%81%E4%BF%A1%E6%81%AF%E7%9A%84%E7%95%99%E6%A1%A3/">
<span class="md-ellipsis">
    一些重要信息的留档
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E8%A2%AB%E9%99%90%E5%88%B6%E5%9C%A8%E5%A3%B0%E9%80%9F/">
<span class="md-ellipsis">
    为什么会被限制在声速
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%B9%B1%E5%BA%8F%E5%A4%84%E7%90%86%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/">
<span class="md-ellipsis">
    乱序处理器学习指南
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1/">
<span class="md-ellipsis">
    交叉熵损失
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%AE%9A%E7%82%B9%E8%A7%A3%E7%AE%97%E6%96%B9%E6%B3%95-%E6%AF%94%E4%BE%8B%E6%B3%95/">
<span class="md-ellipsis">
    传统的定点解算方法-比例法
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%BC%A0%E7%BB%9F%E7%9A%84%E5%AE%9A%E7%82%B9%E8%A7%A3%E7%AE%97%E6%96%B9%E6%B3%95/">
<span class="md-ellipsis">
    传统的定点解算方法
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/">
<span class="md-ellipsis">
    体系结构
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E4%BD%9C%E4%B8%9A%20prompt/">
<span class="md-ellipsis">
    作业 prompt
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%85%9A%E5%9B%A2%E4%BA%8B%E5%8A%A1/">
<span class="md-ellipsis">
    党团事务
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%85%9A%E7%AB%A0%E3%80%81%E5%85%9A%E6%97%97%E3%80%81%E4%BA%8C%E5%8D%81%E5%A4%A7%E6%8A%A5%E5%91%8A%E3%80%81%E5%85%A5%E5%85%9A%E6%B5%81%E7%A8%8B%E3%80%81%E5%9B%9B%E5%8F%B2%E5%AD%A6%E4%B9%A0%E3%80%81%E5%85%9A%E5%86%85%E7%BA%AA%E5%BE%8B%E3%80%81%E4%B8%A4%E4%B8%AA%E7%A1%AE%E7%AB%8B%E3%80%81%E4%B8%A4%E4%B8%AA%E4%B8%80%E7%99%BE%E5%B9%B4%E5%A5%8B%E6%96%97%E7%9B%AE%E6%A0%87%E3%80%81%E5%85%9A%E5%86%85%E5%85%AD%E5%A4%A7%E7%BA%AA%E5%BE%8B%E3%80%81%E4%BC%9F%E5%A4%A7%E5%BB%BA%E5%85%9A%E7%B2%BE%E7%A5%9E%E3%80%81%E4%B8%AD%E5%9B%BD%E5%85%B1%E4%BA%A7%E5%85%9A%E4%BA%BA%E7%9A%84%E7%B2%BE%E7%A5%9E%E8%B0%B1%E7%B3%BB%E4%BB%A5%E5%8F%8A%E9%83%A8%E5%88%86%E6%8E%88%E8%AF%BE%E5%86%85%E5%AE%B9/">
<span class="md-ellipsis">
    党章、党旗、二十大报告、入党流程、四史学习、党内纪律、两个确立、两个一百年奋斗目标、党内六大纪律、伟大建党精神、中国共产党人的精神谱系以及部分授课内容
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%85%A5%E5%85%9A%E6%80%9D%E6%83%B3%E6%8A%A5%E5%91%8A2/">
<span class="md-ellipsis">
    入党思想报告2
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%85%A5%E5%85%9A%E7%94%B3%E8%AF%B7%E4%B9%A6/">
<span class="md-ellipsis">
    入党申请书
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%85%B7%E4%BD%93%E6%A8%A1%E5%9D%97%E8%AF%B4%E6%98%8E/">
<span class="md-ellipsis">
    具体模块说明
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%87%B8%E4%BC%98%E5%8C%96/">
<span class="md-ellipsis">
    凸优化
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/">
<span class="md-ellipsis">
    函数式编程
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%8A%A0%E5%AF%86%E5%8E%9F%E7%90%86/">
<span class="md-ellipsis">
    加密原理
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%8D%95%E4%BD%8D%E5%9B%9B%E5%85%83%E6%95%B0/">
<span class="md-ellipsis">
    单位四元数
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%8D%95%E8%AF%8D%E9%A2%98%E7%9B%AE%E8%A7%A3%E7%AD%94/">
<span class="md-ellipsis">
    单词题目解答
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%AE%8C%E6%95%B4%E7%9A%84%E6%9E%84%E5%BB%BA/">
<span class="md-ellipsis">
    另一个完整的构建
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%9B%BE%E5%BD%A2%E5%AD%A6/">
<span class="md-ellipsis">
    图形学
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%A4%8D%E7%8E%B0%E8%AE%BA%E6%96%87/">
<span class="md-ellipsis">
    复现论文
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/">
<span class="md-ellipsis">
    多模态学习指南
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%A4%9A%E6%A8%A1%E6%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%92/">
<span class="md-ellipsis">
    多模态深度学习研究方向学习规划
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%20docker/">
<span class="md-ellipsis">
    如何使用 docker
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%AD%A6%E6%9C%AF%E5%86%99%E4%BD%9C%E5%8A%A8%E8%AF%8D/">
<span class="md-ellipsis">
    学术写作动词
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/">
<span class="md-ellipsis">
    并行计算
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E5%BE%85%E5%88%86%E7%B1%BB/">
<span class="md-ellipsis">
    待分类
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%80%9D%E6%BA%90%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/">
<span class="md-ellipsis">
    思源学习计划
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%88%91%E7%9A%84%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF/">
<span class="md-ellipsis">
    我的个人信息
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%88%91%E8%87%AA%E5%B7%B1%E7%9A%84%20AI%20%E6%8A%80%E6%9C%AF%E6%A0%88/">
<span class="md-ellipsis">
    我自己的 AI 技术栈
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%8E%92%E7%89%88%E3%80%81blog/">
<span class="md-ellipsis">
    排版、blog
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1_README/">
<span class="md-ellipsis">
    数学建模_README
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%96%87%E6%A1%A3%E6%B1%82%E5%8A%A9%E7%9A%84prompt/">
<span class="md-ellipsis">
    文档求助的prompt
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%9B%B4%E5%8A%A0%E8%AF%A6%E7%BB%86%E7%9A%84%E5%AE%9E%E4%BE%8B/">
<span class="md-ellipsis">
    更加详细的实例
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%9B%B4%E8%BF%9B%E4%B8%80%E6%AD%A5%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8D%97/">
<span class="md-ellipsis">
    更进一步的学习指南
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%9C%80%E7%BB%88%E6%A8%A1%E5%9E%8B/">
<span class="md-ellipsis">
    最终模型
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%9D%82%E4%B9%B1%E7%9A%84%E4%B8%9C%E8%A5%BF/">
<span class="md-ellipsis">
    杂乱的东西
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%9F%A5%E6%89%BE%206Dpose%20%E7%9A%84%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE/">
<span class="md-ellipsis">
    查找 6Dpose 的相关文献
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%B5%8B%E8%B7%9D%E4%B8%8E%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/">
<span class="md-ellipsis">
    测距与深度估计
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE/">
<span class="md-ellipsis">
    激光雷达
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%E5%90%91%E9%87%8F/">
<span class="md-ellipsis">
    独热编码向量
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%94%B5%E6%8E%A7%E4%BB%A3%E7%A0%81/">
<span class="md-ellipsis">
    电控代码
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%9B%B8%E6%9C%BA%E6%A0%87%E5%AE%9A/">
<span class="md-ellipsis">
    相机标定
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%A1%AC%E4%BB%B6-%E7%9B%B8%E6%9C%BA/">
<span class="md-ellipsis">
    硬件-相机
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%A5%9E%E5%A5%87%E7%9A%84%E7%BD%91%E7%AB%99/">
<span class="md-ellipsis">
    神奇的网站
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%A7%91%E7%A0%94/">
<span class="md-ellipsis">
    科研
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%A7%91%E7%A0%94%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/">
<span class="md-ellipsis">
    科研学习计划
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%A8%8B%E5%BA%8F%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84%E6%A8%A1%E5%9E%8B/">
<span class="md-ellipsis">
    程序使用到的模型
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%BC%96%E8%AF%91/">
<span class="md-ellipsis">
    编译
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/">
<span class="md-ellipsis">
    编译优化
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%BC%96%E8%AF%91%E5%85%A5%E9%97%A8/">
<span class="md-ellipsis">
    编译入门
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E7%BC%96%E8%AF%91%E8%BF%9B%E9%98%B6/">
<span class="md-ellipsis">
    编译进阶
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%81%94%E7%B3%BB%E5%AF%BC%E5%B8%88%E9%82%AE%E4%BB%B6/">
<span class="md-ellipsis">
    联系导师邮件
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%87%AA%E5%AD%A6%E7%BD%91%E7%AB%99/">
<span class="md-ellipsis">
    自学网站
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%87%AA%E5%B7%B1%E7%9A%84csapp%E7%AC%94%E8%AE%B0/">
<span class="md-ellipsis">
    自己的csapp笔记
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/">
<span class="md-ellipsis">
    自我介绍
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">
<span class="md-ellipsis">
    计算机网络
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80/">
<span class="md-ellipsis">
    计算机网络安全基础
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%AF%86%E5%88%AB%E6%95%B0%E5%AD%97/">
<span class="md-ellipsis">
    识别数字
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%AF%BE%E7%A8%8B/">
<span class="md-ellipsis">
    课程
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E8%BD%AC%E4%B8%93%E4%B8%9A%E6%B1%82%E5%8A%A9/">
<span class="md-ellipsis">
    转专业求助
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../%E9%A1%B9%E7%9B%AE%E5%AE%9E%E8%B7%B5/">
<span class="md-ellipsis">
    项目实践
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#1">
<span class="md-ellipsis">
      先决条件1
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
<span class="md-ellipsis">
      循环神经网络
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rnns">
<span class="md-ellipsis">
      RNNs能做什么；选择时间步长
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rnn">
<span class="md-ellipsis">
      普通的RNN
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/WncFht/test/edit/main/docs/graph/Written Memories_notes.md" title="edit.link.title">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"></path></svg>
</a>
<h1>Written Memories_notes</h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>7097<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 17H7V3h14m0-2H7a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2M3 5H1v16a2 2 0 0 0 2 2h16v-2H3m12.96-10.71-2.75 3.54-1.96-2.36L8.5 15h11z"></path></svg></span> <span>7<span class="heti-spacing"> </span></span>张图片 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>24<span class="heti-spacing"> </span></span>分钟</p>
</div>
<p>切换导航</p>
<p>书面记忆：理解、推导和扩展<span><span class="heti-spacing"> </span>LSTM</span><br/>
2016年7月26日，星期二</p>
<p>当我第一次接触到长短期记忆网络（LSTMs）时，我很难忽视它们的复杂性。我不明白它们为什么会被设计成现在这个样子，只知道它们有效。结果发现，<span>LSTMs<span class="heti-spacing"> </span></span>是可以被理解的，而且尽管它们表面上看起来很复杂，但实际上<span class="heti-skip"><span class="heti-spacing"> </span>LSTMs<span class="heti-spacing"> </span></span>是基于一些非常简单，甚至美丽的关于神经网络的洞察。当我最初学习循环神经网络（RNNs）时，我希望我能拥有这篇文章。</p>
<p>在这篇文章中，我们做几件事情：</p>
<p>我们将定义并描述一般的<span><span class="heti-spacing"> </span>RNNs</span>，重点关注导致<span class="heti-skip"><span class="heti-spacing"> </span>LSTM<span class="heti-spacing"> </span></span>发展的普通<span class="heti-skip"><span class="heti-spacing"> </span>RNNs<span class="heti-spacing"> </span></span>的局限性。<br/>
我们将描述LSTM架构背后的直觉，这将使我们能够建立并推导出LSTM。在此过程中，我们将推导出GRU。我们还将推导出一个伪LSTM，我们将看到它在原理和性能上都优于标准LSTM。<br/>
然后，我们将扩展这些直觉，以展示它们如何直接导致一些最近和令人兴奋的架构：高速公路和残差网络，以及神经图灵机。<br/>
这是一篇关于理论的文章，而不是实现。关于如何使用Tensorflow实现RNNs，请查看我的文章《Tensorflow中的循环神经网络I》和《Tensorflow中的循环神经网络II》。</p>
<p>内容<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>快速链接：<br/>
循环神经网络<br/>
RNNs能做什么；选择时间步长<br/>
普通的RNN<br/>
信息形态变化和消失以及爆炸性敏感性<br/>
消失敏感性的数学充分条件<br/>
避免消失梯度的最小权重初始化<br/>
通过时间反向传播和消失敏感性<br/>
处理消失和爆炸性梯度<br/>
书面记忆：LSTM背后的直觉<br/>
使用选择性控制和协调写作<br/>
作为选择性机制的门控<br/>
将门控粘合在一起以推导出原型LSTM<br/>
三个工作模型：标准化原型、GRU和伪LSTM<br/>
推导出LSTM<br/>
带窥孔的LSTM<br/>
基本LSTM和伪LSTM的实证比较<br/>
扩展LSTM  </p>
<h3 id="1">先决条件<span><span class="heti-spacing"> </span>1</span><a class="headerlink" href="#1" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<p>这篇文章假设读者已经熟悉以下内容：</p>
<ol>
<li>前馈神经网络  </li>
<li>反向传播  </li>
<li>基础线性代数<br/>
我们将回顾所有其他内容，从一般RNNs开始。</li>
</ol>
<h2 id="_1">循环神经网络<a class="headerlink" href="#_1" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h2>
<p>从一刻到下一刻，我们的大脑作为一个函数运作：它接受来自我们感官（外部）和我们的思想（内部）的输入，并以行动（外部）和新思想（内部）的形式产生输出。我们看到一只熊，然后想到“熊”。我们可以模拟这种行为，使用前馈神经网络：我们可以教会前馈神经网络在显示熊的图像时思考“熊”。</p>
<p>但我们的大脑不是一个一次性函数。它随时间反复运行。我们看到了一只熊，然后想到“熊”，然后想到“跑”。重要的是，将熊的图像转化为“熊”思想的同一个函数也转化了“熊”的思想为“跑”的思想。它是一个循环函数，我们可以用循环神经网络（RNN）来模拟。</p>
<p><span>RNN<span class="heti-spacing"> </span></span>是由相同的前馈神经网络组成的，每个时刻或时间步骤都有一个，我们将称之为“<span>RNN<span class="heti-spacing"> </span></span>单元”。注意，这是比通常给出的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>定义（“普通”<span>RNN<span class="heti-spacing"> </span></span>作为<span class="heti-skip"><span class="heti-spacing"> </span>LSTM<span class="heti-spacing"> </span></span>的前身稍后介绍）要宽泛得多的定义。这些单元操作它们自己的输出，允许它们被组合。它们也可以操作外部输入并产生外部输出。这里是单个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元的图表：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020095758.png"><img alt="Pasted image 20241020095758.png" src="../../assets/images/Pasted%20image%2020241020095758.png"/></a><br/>
这里是三个组合RNN单元的图表：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020095829.png"><img alt="Pasted image 20241020095829.png" src="../../assets/images/Pasted%20image%2020241020095829.png"/></a><br/>
你可以将递归输出视为传递给下一个时间步的“状态”。因此，一个RNN单元接受先前的状态和一个（可选的）当前输入，并产生当前状态和一个（可选的）当前输出。</p>
<p>这里是<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元的代数描述：</p>
<p>其中：</p>
<p><span>[ s_t ]<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>[ s_{t-1} ]<span class="heti-spacing"> </span></span>是我们当前和先前的状态，<br/>
[ o_t ] 是我们（可能为空的）当前输出，<br/>
[ x_t ] 是我们（可能为空的）当前输入，和<br/>
[ f ] 是我们的循环函数。<br/>
我们的大脑在原地运作：当前的神经活动取代了过去的神经活动。我们也可以将RNN看作是在原地运作：因为RNN单元是相同的，它们可以被视为同一个对象，RNN单元的“状态”在每个时间步骤中被覆盖。这里是这种框架的图表：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020100251.png"><img alt="Pasted image 20241020100251.png" src="../../assets/images/Pasted%20image%2020241020100251.png"/></a><br/>
大多数RNN的介绍都从这个“单细胞循环”框架开始，但我认为你会发现顺序框架更直观，特别是当考虑反向传播时。当从单细胞循环框架开始时，RNN被称为“展开”以获得上面的顺序框架。</p>
<h2 id="rnns"><span>RNNs<span class="heti-spacing"> </span></span>能做什么；选择时间步长<a class="headerlink" href="#rnns" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h2>
<p>上面描述的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>结构非常通用。理论上，它可以做任何事情：如果我们给每个单元内的神经网络至少一个隐藏层，每个单元就成为一个通用函数逼近器。这意味着一个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元可以模拟任何函数，因此，理论上，一个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>可以完美地模拟我们的大脑。尽管我们知道大脑理论上可以以这种方式建模，但实际设计和训练一个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>来做到这一点是完全不同的事情。然而，我们正在取得很好的进展。</p>
<p>有了这个大脑的类比，我们所需要做的就是看看我们如何使用<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>来处理一个任务，就是问一个人类会如何处理相同的任务。</p>
<p>以英文到法文翻译为例。一个人阅读一个英文句子（“猫坐在垫子上”<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，暂停，然后写出法文翻译（“猫坐在垫子上”<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。为了用<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>模拟这种行为，我们唯一需要做出的选择（除了设计<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元本身，现在我们将其视为一个黑盒子）是决定应该使用的时间步长是什么，这决定了输入和输出的形式，或者<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>如何与外部世界互动。</p>
<p>一个选择是根据内容设置时间步长。也就是说，我们可能使用整个句子作为一个时间步长，在这种情况下，我们的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>只是一个前馈网络：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020100516.png"><img alt="Pasted image 20241020100516.png" src="../../assets/images/Pasted%20image%2020241020100516.png"/></a><br/>
翻译单个句子时，最终状态无关紧要。然而，如果句子是正在翻译的段落的一部分，那么它可能会很重要，因为它包含了关于之前句子的信息。请注意，上面的初始状态被指示为空白，但在评估单个序列时，将初始状态训练为变量可能是有用的。也许最好的“序列开始”状态表示不一定是空白零状态。</p>
<p>或者，我们可以说每个单词或每个字符是一个时间步长。这里是一个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>在每个单词的基础上翻译“the cat sat”的图示：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020100644.png"><img alt="Pasted image 20241020100644.png" src="../../assets/images/Pasted%20image%2020241020100644.png"/></a></p>
<p>在第一个时间步长之后，状态包含了“the”的内部表示；在第二个之后<heti-adjacent class="heti-adjacent-quarter">，</heti-adjacent>“the cat”；在第三个之后<heti-adjacent class="heti-adjacent-quarter">，</heti-adjacent>“the cat sat”。网络在前三个时间步长中没有产生任何输出。当它接收到一个空白输入时，它开始产生输出，此时它知道输入已经结束。当它完成产生输出时，它产生一个空白输出以表示它已经完成。</p>
<p>在实践中，即使像深度<span class="heti-skip"><span class="heti-spacing"> </span>LSTMs<span class="heti-spacing"> </span></span>这样的强大<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>架构也可能在多个任务上表现不佳（这里有两个：阅读，然后翻译<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。为了适应这一点，我们可以将网络分成多个<span><span class="heti-spacing"> </span>RNNs</span>，每个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>都专门处理一个任务。在这个例子中，我们将使用一个“编码器”网络来读取英文（蓝色）和一个单独的“解码器”网络来读取法文（橙色<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020100811.png"><img alt="Pasted image 20241020100811.png" src="../../assets/images/Pasted%20image%2020241020100811.png"/></a><br/>
此外，如上图所示，解码器网络正在被输入最后一个真实值（即，在训练期间的目标值，在测试期间网络之前的翻译单词选择）。有关RNN编码器-解码器模型的示例，请参见Cho等人（2014年）。</p>
<p>请注意，拥有两个独立的网络仍然符合单个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>的定义：我们可以将递归函数定义为一个拆分函数，它接受其其他输入，指定要使用的函数拆分。</p>
<p>时间步长不必基于内容；它可以是一个实际的时间单位。例如，我们可能认为时间步长是一秒钟，并强制执行每秒<span class="heti-skip"><span class="heti-spacing"> </span>5<span class="heti-spacing"> </span></span>个字符的阅读速度。前三个时间步长的输入将是<span><span class="heti-spacing"> </span>c</span>、<span>at sa<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>t on</span>。</p>
<p>我们还可以做更有趣的事情：我们可以让<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>决定何时准备好移动到下一个输入，甚至是什么输入。这与人类可能专注于某些单词或短语一段时间以翻译它们或可能回顾源的方式类似。为了做到这一点，我们使用<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>的输出（一个外部动作）来动态确定其下一个输入。例如，我们可能让<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>输出动作，如“再次阅读最后一个输入”<heti-adjacent class="heti-adjacent-quarter">，</heti-adjacent>“回溯<span class="heti-skip"><span class="heti-spacing"> </span>5<span class="heti-spacing"> </span></span>个时间步长的输入”等。成功的基于注意力的翻译模型就是在此基础上的：它们在每个时间步长接受整个英文序列，它们的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元决定哪些部分与它们目前正在产生的当前法文单词最相关。</p>
<p>这个英语到法语的翻译示例并没有什么特别之处。无论我们选择哪种人类任务，我们都可以通过选择不同的时间步长来构建不同的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>模型。我们甚至可以将像手写数字识别这样的任务重新定义为多个时间步长的任务，对于这种任务，一次性函数（单时间步长）是典型的方法。实际上，亲自看看一些<span class="heti-skip"><span class="heti-spacing"> </span>MNIST<span class="heti-spacing"> </span></span>数字，观察你需要比其他数字更长时间地关注它们。前馈神经网络不能表现出这种行为；<span>RNN<span class="heti-spacing"> </span></span>可以。</p>
<h2 id="rnn">普通的<span><span class="heti-spacing"> </span>RNN</span><a class="headerlink" href="#rnn" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h2>
<p>现在我们已经了解了大局，让我们来看一下<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元的内部。最基本的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元是一个单层神经网络，其输出用作<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元的当前（外部）输出和当前状态：<br/>
<a class="glightbox" data-desc-position="bottom" data-height="auto" data-type="image" data-width="80%" href="../../assets/images/Pasted%20image%2020241020101530.png"><img alt="Pasted image 20241020101530.png" src="../../assets/images/Pasted%20image%2020241020101530.png"/></a><br/>
请注意，先前的状态向量与当前状态向量的大小相同。如上所述，这对于RNN单元的组合至关重要。这里是普通RNN单元的代数描述：</p>
<div class="arithmatex">\[
s_{t} = \phi (W s_{(t-1)} + U x_{t} + b)
\]</div>
<p>其中：</p>
<ul>
<li><span>[ \phi ]<span class="heti-spacing"> </span></span>是激活函数（例如，sigmoid、tanh、ReLU<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，  </li>
<li><span>[ s_t \in \mathbb{R}^n ]<span class="heti-spacing"> </span></span>是当前状态（和当前输出<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，  </li>
<li><span>[ s_{t-1} \in \mathbb{R}^n ]<span class="heti-spacing"> </span></span>是先前状态，  </li>
<li><span>[ x_t \in \mathbb{R}^m ]<span class="heti-spacing"> </span></span>是当前输入，  </li>
<li><span><span class="arithmatex">\(W \in \mathbb{R}^{n \times n}\)</span> , <span class="arithmatex">\(U \in \mathbb{R}^{m \times n}\)</span> ,<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(b \in \mathbb{R}^n\)</span><span class="heti-spacing"> </span></span>是权重和偏置，和  </li>
<li><span>[ n ]<span class="heti-spacing"> </span></span>和<span class="heti-skip"><span class="heti-spacing"> </span>[ m ]<span class="heti-spacing"> </span></span>是状态和输入大小。<br/>
即使是这种基本的RNN单元也非常强大。尽管它没有满足单一单元内通用函数逼近的标准，但已知一系列组合的普通RNN单元是图灵完备的，因此可以实现任何算法。参见Siegelmann和Sontag（1992）。理论上这很好，但实践中有一个问题：使用反向传播算法训练普通RNNs结果证明是非常困难的，甚至比训练非常深的前馈神经网络更加困难。这种困难是由于信息形态变化和消失和爆炸性敏感性问题，这些问题是由相同的非线性函数重复应用引起的。</li>
</ul>
<p>信息形态变化和消失和爆炸性敏感性<span><span class="heti-spacing"> </span>4</span><br/>
与其考虑大脑，不如将整个世界建模为一个RNN：从每一个时刻到下一个时刻，世界的状态被一个叫做时间的极其复杂的循环函数修改。现在考虑今天发生的一个小变化将如何在一百年后影响世界。可能是像蝴蝶翅膀的扇动最终在世界另一端引起台风。5但也可能我们的今天的行动最终无关紧要。如果爱因斯坦没有发现相对论怎么办？这在1950年代可能会有所不同，但也许那时有人发现了相对论，以至于到了2000年代差异变小，最终到2050年接近零。最后，一个小变化的重要性可能会波动：也许爱因斯坦的发现实际上是由于他的妻子对一只偶然飞过的蝴蝶的评论引起的，以至于蝴蝶在20世纪引发了一个大变化，然后很快就消失了。</p>
<p>在爱因斯坦的例子中，请注意，过去的变化是新信息的引入（相对论<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，更一般地说，新信息的引入是时间流逝（时间的流动）的直接结果。因此，我们可以将信息本身视为由循环函数变形的变化，其影响消失、爆炸或简单地波动。</p>
<p>这种讨论表明，世界（或<span><span class="heti-spacing"> </span>RNN</span>）的状态在不断变化，现在对过去的变化可能非常敏感或非常不敏感：效果可以复合或溶解。这些都是问题，它们扩展到<span><span class="heti-spacing"> </span>RNNs</span>（和前馈神经网络<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>：</p>
<p>信息形态变化</p>
<p>首先，如果信息不断变化，当我们需要它时，就很难适当地利用过去的信息。信息的最佳可用状态可能在某个时刻已经发生过。除了学习如何在今天利用信息（如果它以原始的可用形式存在<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，我们还必须学会如何从当前状态解码原始状态，如果那是可能的话。这导致了困难的学习和糟糕的结果。6</p>
<p>在普通<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>中很容易证明信息形态变化的发生。实际上，假设<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元能够在没有外部输入的情况下完全保持其先前状态。那么<span class="heti-skip"><span class="heti-spacing"> </span>[ F(x) = \phi(W s_{t-1} + b) ]<span class="heti-spacing"> </span></span>是关于<span class="heti-skip"><span class="heti-spacing"> </span>[ s_{t-1} ]<span class="heti-spacing"> </span></span>的恒等函数。但恒等函数是线性的，而<span class="heti-skip"><span class="heti-spacing"> </span>[ F(x) ]<span class="heti-spacing"> </span></span>是非线性的，所以我们有一个矛盾。因此，<span>RNN<span class="heti-spacing"> </span></span>单元不可避免地会在一个时间步骤到下一个时间步骤之间变形状态。即使是输出<span class="heti-skip"><span class="heti-spacing"> </span>[ s_t = x_t ]<span class="heti-spacing"> </span></span>这样的简单任务对于普通<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>来说也是不可能的。</p>
<p>这是一些圈子中所谓的退化问题的根源。参见，例如，<span>He<span class="heti-spacing"> </span></span>等人（2015<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。<span>He<span class="heti-spacing"> </span></span>等人的作者声称这是“意想不到的”和“违反直觉的”，但我希望这次讨论表明，退化问题，或信息形态变化，实际上是相当自然的（并且在许多情况下是可取的<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。我们将在下面看到，尽管信息形态变化不是引入<span class="heti-skip"><span class="heti-spacing"> </span>LSTMs<span class="heti-spacing"> </span></span>的原始动机之一，但<span class="heti-skip"><span class="heti-spacing"> </span>LSTM<span class="heti-spacing"> </span></span>背后的原则碰巧有效地解决了这个问题。事实上，<span>He<span class="heti-spacing"> </span></span>等人（2015）使用的残差网络的有效性是<span class="heti-skip"><span class="heti-spacing"> </span>LSTMs<span class="heti-spacing"> </span></span>的基本原则的结果。</p>
<p>消失和爆炸性梯度</p>
<p>第二，我们使用反向传播算法训练<span><span class="heti-spacing"> </span>RNN</span>。但反向传播是基于梯度的算法，消失和爆炸性“敏感性”只是另一种说法，即消失和爆炸性梯度（后者是被接受的术语，但我认为前者更具描述性<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>。如果梯度爆炸，我们无法训练我们的模型。如果它们消失，我们就很难学习长期依赖关系，因为反向传播对最近的干扰过于敏感。这使得训练变得困难。</p>
<p>我将很快回到通过反向传播训练<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>的困难，但首先我想给出一个简短的数学证明，说明普通<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>容易受到消失梯度的影响，以及我们可以在训练开始时做些什么来帮助避免这一点。</p>
<p>消失敏感性的数学充分条件<br/>
在这一部分，我给出了普通RNN中消失敏感性的充分条件的数学证明。这部分有点数学，你可以安全地跳过证明的细节。它本质上与Pascanu等人（2013）中的类似结果的证明相同，但我认为你会发现这个介绍更容易理解。这里的证明还利用了中值定理，比Pascanu等人更进一步，达到了一个稍微更强的结果，有效地显示了消失的因果关系而不是消失的敏感性。7请注意，关于消失和爆炸梯度的数学分析可以追溯到20世纪90年代初，在Bengio等人（1994）和Hochreiter（1991）（最初是德语，在Hochreiter和Schmidhuber（1997）中总结了相关内容）。</p>
<p>设<span class="heti-skip"><span class="heti-spacing"> </span>[ s_t ]<span class="heti-spacing"> </span></span>是我们在时间<span class="heti-skip"><span class="heti-spacing"> </span>[ t ]<span class="heti-spacing"> </span></span>的状态向量，设<span class="heti-skip"><span class="heti-spacing"> </span>[ \Delta v ]<span class="heti-spacing"> </span></span>是由状态向量在时间<span class="heti-skip"><span class="heti-spacing"> </span>[ t ]<span class="heti-spacing"> </span></span>的<span class="heti-skip"><span class="heti-spacing"> </span>[ \Delta s_t ]<span class="heti-spacing"> </span></span>引起的向量<span class="heti-skip"><span class="heti-spacing"> </span>[ v ]<span class="heti-spacing"> </span></span>的变化。我们的目标是提供一个数学上充分的条件，使得由状态在时间步骤<span class="heti-skip"><span class="heti-spacing"> </span>[ t ]<span class="heti-spacing"> </span></span>的变化引起的在时间步骤<span class="heti-skip"><span class="heti-spacing"> </span>[ t+k ]<span class="heti-spacing"> </span></span>的状态变化随着<span class="heti-skip"><span class="heti-spacing"> </span>[ n \to \infty ]<span class="heti-spacing"> </span></span>消失；即，我们将证明以下条件的充分条件：</p>
<div class="arithmatex">\[ \lim_{k \to \infty} \frac{\Delta s_{t+k}}{\Delta s_t} = 0. \]</div>
<p>相比之下，<span>Pascanu<span class="heti-spacing"> </span></span>等人（2013）证明了以下结果的相同充分条件，这可以很容易地扩展以获得上述结果：</p>
<div class="arithmatex">\[ \lim_{k \to \infty} \frac{\partial s_{t+k}}{\partial s_t} = 0. \]</div>
<p>首先，根据我们对普通<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元的定义，我们有：</p>
<div class="arithmatex">\[ s_{t+1} = \phi(z_t) \text{ where } z_t = W s_t + U x_{t+1} + b. \]</div>
<p>应用多变量中值定理，我们得到存在<span class="heti-skip"><span class="heti-spacing"> </span>[ c \in [z_t, z_t + \Delta z_t] )<span class="heti-spacing"> </span></span>使得：</p>
<div class="arithmatex">\[ \Delta s_{t+1} = [\phi'(c)] \Delta z_t = [\phi'(c)] \Delta (W s_t). = [\phi'(c)] W \Delta s_t. \]</div>
<p>现在设<span class="heti-skip"><span class="heti-spacing"> </span>[ |A| )<span class="heti-spacing"> </span></span>表示矩阵<span class="heti-skip"><span class="heti-spacing"> </span>2-<span class="heti-spacing"> </span></span>范数，<span>[ |v| )<span class="heti-spacing"> </span></span>表示欧几里得向量范数，并定义：</p>
<div class="arithmatex">\[ \gamma = \sup_{c \in [z_t, z_t + \Delta z_t]} \|[\phi'(c)]\| \]</div>
<p>请注意，对于逻辑<span><span class="heti-spacing"> </span>sigmoid</span>，[ \gamma \leq \frac{1}{4} )，对于<span><span class="heti-spacing"> </span>tanh</span>，[ \gamma \leq 1 )。8</p>
<p>取两边的向量范数，我们得到，其中第一个不等式来自于<span class="heti-skip"><span class="heti-spacing"> </span>2-<span class="heti-spacing"> </span></span>范数的定义（应用了两次<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，第二个来自于上确界的定义：</p>
<div class="arithmatex">\[ |\Delta s_{t+1}| = |[\phi'(c)] W \Delta s_t| \leq \|[\phi'(c)]\| \|W\| |\Delta s_t| \leq \gamma \|W\| |\Delta s_t| = \|\gamma W\| |\Delta s_t|. \]</div>
<p>（1）</p>
<p>通过在<span class="heti-skip"><span class="heti-spacing"> </span>[ k ]<span class="heti-spacing"> </span></span>个时间步骤中展开这个公式，我们得到<span><span class="heti-spacing"> </span>[ |\Delta s_{t+k}| \leq |\gamma W|^k |\Delta s_t| )</span>，使得：</p>
<div class="arithmatex">\[ \frac{|\Delta s_{t+k}|}{|\Delta s_t|} \leq \|\gamma W\|^k. \]</div>
<p>因此，如果<span><span class="heti-spacing"> </span>[ |\gamma W| &lt; 1 )</span>，我们有<span class="heti-skip"><span class="heti-spacing"> </span>[ \frac{|\Delta s_{t+k}|}{|\Delta s_t| )<span class="heti-spacing"> </span></span>随着时间指数级减少，并且我们证明了以下条件的充分条件：</p>
<div class="arithmatex">\[ \lim_{k \to \infty} \frac{\Delta s_{t+k}}{\Delta s_t} = 0. \]</div>
<p>当<span class="heti-skip"><span class="heti-spacing"> </span>[ |\gamma W| &lt; 1 )<span class="heti-spacing"> </span></span>时？<span>[ \gamma )<span class="heti-spacing"> </span></span>对于逻辑<span class="heti-skip"><span class="heti-spacing"> </span>sigmoid<span class="heti-spacing"> </span></span>有界于<span><span class="heti-spacing"> </span>[ \frac{1}{4} )</span>，对于<span><span class="heti-spacing"> </span>tanh</span>，有界于<span><span class="heti-spacing"> </span>1</span>。这告诉我们消失梯度的充分条件是<span class="heti-skip"><span class="heti-spacing"> </span>[ |W| )<span class="heti-spacing"> </span></span>必须小于<span class="heti-skip"><span class="heti-spacing"> </span>4<span class="heti-spacing"> </span></span>或<span><span class="heti-spacing"> </span>1</span>，分别。</p>
<p>从这一点上，我们立即得到的教训是，如果我们的权重初始化对于<span class="heti-skip"><span class="heti-spacing"> </span>[ W )<span class="heti-spacing"> </span></span>太小，我们的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>可能一开始就无法学习任何东西，由于梯度消失。让我们现在扩展这个分析，以确定一个理想的权重初始化。</p>
<p>避免消失梯度的最小权重初始化<br/>
找到一种不会立即受到这个问题影响的权重初始化是有益的。扩展上述分析，找到使我们尽可能接近等式（1）的权重[ W )的初始化，会导致一个不错的结果。</p>
<p>首先，让我们假设<span class="heti-skip"><span class="heti-spacing"> </span>[ \phi = \text{tanh} )<span class="heti-spacing"> </span></span>并取<span><span class="heti-spacing"> </span>[ \gamma = 1 )</span>，<span>9<span class="heti-spacing"> </span></span>但你同样可以假设<span class="heti-skip"><span class="heti-spacing"> </span>[ \phi = \sigma )<span class="heti-spacing"> </span></span>并取<span class="heti-skip"><span class="heti-spacing"> </span>[ \gamma = \frac{1}{4} )<span class="heti-spacing"> </span></span>以获得不同的结果。</p>
<p>我们的目标是找到一个<span class="heti-skip"><span class="heti-spacing"> </span>[ W )<span class="heti-spacing"> </span></span>的初始化，使得：</p>
<div class="arithmatex">\[ \|\gamma W\| = 1. \]</div>
<p>我们在等式（1）中尽可能接近等式。<br/>
从第一点，由于我们取[ \gamma )为1，我们有[ |W| = 1 )。从第二点，我们得到我们应该尝试将[ W )的所有奇异值设置为1，而不仅仅是最大的。然后，如果[ W )的所有奇异值都等于1，这意味着[ W )的每个列的范数是1（因为每个列是[ W e_i )对于一些基本基向量[ e_i )，我们有[ |W e_i| = |e_i| = 1 )）。这意味着对于列[ j )我们有：</p>
<div class="arithmatex">\[ \sum_{i} w_{ij}^2 = 1 \]</div>
<p>在列<span class="heti-skip"><span class="heti-spacing"> </span>[ j )<span class="heti-spacing"> </span></span>中有<span class="heti-skip"><span class="heti-spacing"> </span>[ n )<span class="heti-spacing"> </span></span>个条目，我们从相同的随机分布中选择每个条目，所以让我们找到一个随机权重<span class="heti-skip"><span class="heti-spacing"> </span>[ w )<span class="heti-spacing"> </span></span>的分布，使得：</p>
<div class="arithmatex">\[ n E(w^2) = 1 \]</div>
<p>现在让我们假设我们希望在区间<span class="heti-skip"><span class="heti-spacing"> </span>[ [-R, R] )<span class="heti-spacing"> </span></span>中均匀地初始化<span><span class="heti-spacing"> </span>[ w )</span>。然后<span class="heti-skip"><span class="heti-spacing"> </span>[ w )<span class="heti-spacing"> </span></span>的均值为<span><span class="heti-spacing"> </span>0</span>，因此，根据定义，<span>[ E(w^2) )<span class="heti-spacing"> </span></span>是它的方差，[ V(w) )。在区间<span class="heti-skip"><span class="heti-spacing"> </span>[ [a, b] )<span class="heti-spacing"> </span></span>上的均匀分布的方差由<span class="heti-skip"><span class="heti-spacing"> </span>[ \frac{(b-a)^2}{12} )<span class="heti-spacing"> </span></span>给出，从中我们得到<span><span class="heti-spacing"> </span>[ V(w) = \frac{R^2}{3} )</span>。将这个代入我们的方程，我们得到：</p>
<div class="arithmatex">\[ n \frac{R^2}{3} = 1 \]</div>
<p>所以：</p>
<div class="arithmatex">\[ R = \sqrt{\frac{3}{n}} \]</div>
<p>这表明我们应该从区间<span class="heti-skip"><span class="heti-spacing"> </span>[ [-\sqrt{\frac{3}{n}}, \sqrt{\frac{3}{n}}] )<span class="heti-spacing"> </span></span>上的均匀分布中初始化我们的权重。</p>
<p>这是一个不错的结果，因为它是方差权重矩阵的<span class="heti-skip"><span class="heti-spacing"> </span>Xavier-Glorot<span class="heti-spacing"> </span></span>初始化，但它是由一个不同的想法驱动的。<span>Xavier-Glorot<span class="heti-spacing"> </span></span>初始化，由<span class="heti-skip"><span class="heti-spacing"> </span>Glorot<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>Bengio</span>（2010）引入，在实践中已被证明是一种有效的权重初始化处方。更一般地，<span>Xavier-Glorot<span class="heti-spacing"> </span></span>处方适用于在具有其导数在原点附近为一的激活函数的层中使用的<span class="heti-skip"><span class="heti-spacing"> </span>[ m \times n )<span class="heti-spacing"> </span></span>权重矩阵，并且说我们应该根据区间的均匀分布初始化我们的权重：<br/>
[ [-\sqrt{\frac{6}{m+n}}, \sqrt{\frac{6}{m+n}}] )。</p>
<p>你可以很容易地修改上述分析，以获得在使用逻辑<span><span class="heti-spacing"> </span>sigmoid</span>（使用<span><span class="heti-spacing"> </span>[ \gamma = \frac{1}{4} )</span>）和根据不同的随机分布（例如，高斯分布）初始化权重时的初始化处方。</p>
<p>通过时间的反向传播和消失敏感性<br/>
用反向传播训练RNN与用反向传播训练前馈网络非常相似。由于假设你已经熟悉反向传播，只有几点评论：</p>
<p>我们通过时间反向传播错误</p>
<p>对于<span><span class="heti-spacing"> </span>RNNs</span>，我们需要从当前<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元反向传播错误，通过状态，通过时间，回到先前的<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元。这允许<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>学习捕获长期时间依赖性。由于模型的参数在<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元之间共享（每个<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>单元具有相同的权重和偏置<heti-adjacent class="heti-adjacent-half">）</heti-adjacent>，我们需要分别计算每个时间步骤的梯度，然后将它们加起来。这类似于我们在其他模型中反向传播错误到共享参数的方式，例如卷积网络。</p>
<p>在权重更新频率和准确梯度之间存在权衡</p>
<p>对于所有基于梯度的训练算法，不可避免地存在（1）参数更新频率（向后传递）和（2）准确长期梯度之间的权衡。为了看到这一点，考虑当我们在每个步骤更新梯度，但将错误反向传播超过一个步骤时会发生什么：</p>
<p>在时间<span><span class="heti-spacing"> </span>[ t )</span>，我们使用当前权重<span class="heti-skip"><span class="heti-spacing"> </span>[ W_t )<span class="heti-spacing"> </span></span>计算当前输出和当前状态，<span>[ o_t )<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>[ s_t )</span>。<br/>
其次，我们使用[ o_t )运行向后传递并更新[ W_t )到[ W_{t+1} )。<br/>
第三，在时间[ t+1 )，我们使用[ W_{t+1} )和在第一步中计算的[ s_t )来计算[ o_{t+1} )和[ s_{t+1} )。<br/>
最后，我们使用[ o_{t+1} )运行向后传递。但[ o_{t+1} )是使用[ s_t )计算的，这是使用原始[ W_t )计算的，这意味着我们为时间步骤[ t )的权重计算的梯度是在旧权重[ W_t )下评估的，而不是在当前权重[ W_{t+1} )下。因此，它们只是梯度的估计，如果它是针对当前权重计算的。随着我们进一步反向传播错误，这种效果将更加复杂。<br/>
我们可以通过减少参数更新（向后传递）的频率来计算更准确的梯度，但这可能会导致我们放弃训练速度（这在训练开始时可能特别有害）。注意这与选择用于小批量梯度下降的小批量大小的权衡相似：批量大小越大，梯度估计越准确，但也更少的梯度更新。</p>
<p>我们还可以选择不将错误反向传播超过我们参数更新频率的步骤，但那时我们没有计算关于权重的完整梯度，这只是硬币的另一面；相同的权衡发生。</p>
<p>这种效应在<span class="heti-skip"><span class="heti-spacing"> </span>Williams<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>Zipser</span>（1995）中讨论，它提供了关于计算基于梯度的训练算法的梯度的选项的极好概述。</p>
<p>消失梯度加上共享参数意味着不平衡的梯度流和对最近干扰的过度敏感</p>
<p>考虑一个前馈神经网络。指数级消失的梯度意味着对早期层的权重所做的改变将比对后期层的权重所做的改变小得多。这很糟糕，即使我们对网络进行指数级更长时间的训练，以至于早期层最终学习。为了看到这一点，考虑在训练期间早期层和后期层学习如何相互通信。早期层最初发送粗略的信号，所以后期层很快就变得非常擅长解释这些粗略的信号。但随后早期层被鼓励学习如何产生更好的粗略符号，而不是产生更复杂的符号。</p>
<p><span>RNNs<span class="heti-spacing"> </span></span>的情况更糟，因为与前馈网络不同，早期层和后期层的权重是共享的。这意味着他们不仅可以简单地误解，他们可以直接冲突：对特定权重的梯度可能在早期层是正的，但在后期层是负的，导致总体梯度为负，所以早期层的非学习速度比他们学习的速度更快。用<span class="heti-skip"><span class="heti-spacing"> </span>Hochreiter<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>Schmidhuber</span>（1997）的话说<heti-adjacent class="heti-adjacent-quarter">：</heti-adjacent>“通过时间的反向传播对最近的干扰过于敏感<heti-adjacent class="heti-adjacent-quarter">。</heti-adjacent>”</p>
<p>因此，截断反向传播是有意义的</p>
<p>限制我们在训练中反向传播错误的步数称为截断反向传播。立即注意到，如果我们要拟合的输入<span class="heti-skip"><span class="heti-spacing"> </span>/<span class="heti-spacing"> </span></span>输出序列无限长，我们必须截断反向传播，否则我们的算法将在向后传递时停止。如果序列是有限的但非常长，我们可能仍然需要由于计算不可行而截断反向传播。</p>
<p>然而，即使我们有一台可以瞬间反向传播错误无限步数的超级计算机，上述第<span class="heti-skip"><span class="heti-spacing"> </span>2<span class="heti-spacing"> </span></span>点告诉我们，由于权重更新导致的梯度变得不准确，我们需要截断我们的反向传播。</p>
<p>最后，消失的梯度为截断我们的反向传播创造了另一个原因。如果我们的梯度消失，那么反向传播许多步的梯度将非常小，对训练几乎没有影响。</p>
<p>请注意，我们不仅选择截断反向传播的频率，还选择更新我们的模型参数的频率。参见我关于截断反向传播风格的帖子，了解两种可能的截断方法的实证比较，或参考<span class="heti-skip"><span class="heti-spacing"> </span>Williams<span class="heti-spacing"> </span></span>和<span><span class="heti-spacing"> </span>Zipser</span>（1995）中的讨论。</p>
<p>还有所谓的梯度分量的前向传播</p>
<p>知道一些有用的东西（以防你自己想到）是，反向传播并不是我们训练<span class="heti-skip"><span class="heti-spacing"> </span>RNN<span class="heti-spacing"> </span></span>的唯一选择。而不是反向传播错误，我们也可以向前传播梯度分量，允许我们计算每个时间步骤的权重关于错误的梯度。这种替代算法称为“实时递归学习（RTRL）”。完整的<span class="heti-skip"><span class="heti-spacing"> </span>RTRL<span class="heti-spacing"> </span></span>计算成本过高，不切实际，运行时间为<span><span class="heti-spacing"> </span>[ O(n^</span></p>
<div id="__comments"></div>
<!-- <h3>颜色主题调整</h3>
    <div class="tx-switch">
    <button class="button1" data-md-color-primary="red" style="background-color:red">red</button>
    <button class="button1" data-md-color-primary="pink" style="background-color:pink;color:black">pink</button>
    <button class="button1" data-md-color-primary="purple" style="background-color:purple">purple</button>
    <button class="button1" data-md-color-primary="indigo" style="background-color:indigo">indigo</button>
    <button class="button1" data-md-color-primary="blue" style="background-color:blue">blue</button>
    <button class="button1" data-md-color-primary="cyan" style="background-color:cyan;color:black">cyan</button>
    <button class="button1" data-md-color-primary="teal" style="background-color:teal">teal</button>
    <button class="button1" data-md-color-primary="green" style="background-color:green">green</button>
    <button class="button1" data-md-color-primary="lime" style="background-color:lime;color:black">lime</button>
    <button class="button1" data-md-color-primary="orange" style="background-color:orange;color:black">orange</button>
    <button class="button1" data-md-color-primary="brown" style="background-color:brown;border-radius=3px">brown</button>
    <button class="button1" data-md-color-primary="grey" style="background-color:grey">grey</button>
    <button class="button1" data-md-color-primary="black" style="background-color:black">black</button>
    <button class="button1" data-md-color-primary="white" style="background-color:white;color:black">white</button>
    </div> -->
<!-- Giscus -->
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDONBPLqs4Cja0c" data-emit-metadata="0" data-input-position="bottom" data-lang="zh-CN" data-mapping="pathname" data-reactions-enabled="1" data-repo="WncFht/notes" data-repo-id="R_kgDONBPLqg" data-strict="0" data-theme="preferred_color_scheme" src="https://giscus.app/client.js">
</script>
<script>
    var buttons = document.querySelectorAll("button[data-md-color-primary]")
    buttons.forEach(function(button) {
            button.addEventListener("click", function() {
            var attr = this.getAttribute("data-md-color-primary")
            document.body.setAttribute("data-md-color-primary", attr)
            localStorage.setItem("data-md-color-primary",attr);
            })
    })
    </script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")
</script>
<script>
    var giscus = document.querySelector("script[src*=giscus]")
    
    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light"
        giscus.setAttribute("data-theme", theme) 
    }
    
    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
        var ref = document.querySelector("[data-md-component=palette]")
        ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
            var theme = palette.color.scheme === "slate" ? "dark" : "light"
    
            /* Instruct Giscus to change theme */
            var frame = document.querySelector(".giscus-frame")
            frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
            )
        }
        })
    })
    </script>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
        Copyright © 2024 <a href="https://github.com/WncFht" rel="noopener" target="_blank">WncFht</a>
</div>
    
    
      Powered by
      <a href="https://www.mkdocs.org/" rel="noopener" target="_blank">
        MkDocs
      </a>
      with theme
      <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
        Material
      </a>
      modified by
      <a href="https://github.com/WncFht" rel="noopener" target="_blank">
        WncFht
      </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/WncFht" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.code.annotate", "content.action.view", "navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top", "content.code.copy"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
<script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
<script src="../../js/katex.js"></script>
<script src="../../js/mathjax.js"></script>
<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-chtml.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-chtml-full.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-svg-full.js"></script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>