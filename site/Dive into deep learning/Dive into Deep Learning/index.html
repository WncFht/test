<!DOCTYPE html>
<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="wnc" name="author"/>
<link href="https://WncFht.github.io/note/Dive%20into%20deep%20learning/Dive%20into%20Deep%20Learning/" rel="canonical"/>
<link href="../../tygx_exp/%E4%B8%80%E4%BA%9B%E8%B5%84%E6%BA%90/" rel="prev"/>
<link href="../../summary/202409-10/" rel="next"/>
<link href="../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.5.41" name="generator"/>
<title>Dive into Deep Learning - wnc 的咖啡馆</title>
<link href="../../assets/stylesheets/main.0253249f.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link href="../../css/heti.css" rel="stylesheet"/>
<link href="https://cdn.tonycrane.cc/utils/katex.min.css" rel="stylesheet"/>
<link href="https://cdn.tonycrane.cc/jbmono/jetbrainsmono.css" rel="stylesheet"/>
<link href="https://cdn.tonycrane.cc/lxgw/lxgwscreen.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<link href="../../css/tasklist.css" rel="stylesheet"/>
<link href="../../css/card.css" rel="stylesheet"/>
<link href="../../css/flink.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="indigo" data-md-color-primary="blue-grey" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#dive-into-deep-learning">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="wnc 的咖啡馆" class="md-header__button md-logo" data-md-component="logo" href="../.." title="wnc 的咖啡馆">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            wnc 的咖啡馆
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Dive into Deep Learning
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="切换至夜间模式" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="blue-grey" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="切换至夜间模式">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
<input aria-label="切换至日间模式" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="切换至日间模式">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/WncFht/note" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</div>
<div class="md-source__repository">
    wnc's café
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
          
  
    
  
  Home

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../cs61a/COMPOSING%20PROGRAMS/">
          
  
    
  
  cs61a

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../cs61c/cs61c/">
          
  
    
  
  cs61c

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../slam/%E8%A7%86%E8%A7%89SLAM%E5%8D%81%E5%9B%9B%E8%AE%B2/">
          
  
    
  
  SLAM

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../tygx_exp/eng_fht/">
          
  
    
  
  天元公学生存指南

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="./">
          
  
    
  
  动手学深度学习

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../summary/202409-10/">
          
  
    
  
  总结

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="wnc 的咖啡馆" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="wnc 的咖啡馆">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</a>
    wnc 的咖啡馆
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/WncFht/note" title="前往仓库">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M2 21h18v-2H2M20 8h-2V5h2m0-2H4v10a4 4 0 0 0 4 4h6a4 4 0 0 0 4-4v-3h2a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2"></path></svg>
</div>
<div class="md-source__repository">
    wnc's café
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Home
  </span>
</a>
<label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_1_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
            Home
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../links/">
<span class="md-ellipsis">
    友链
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-ellipsis">
    cs61a
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            cs61a
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61a/COMPOSING%20PROGRAMS/">
<span class="md-ellipsis">
    COMPOSING PROGRAMS
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61a/cs61a/">
<span class="md-ellipsis">
    Cs61a
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-ellipsis">
    cs61c
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            cs61c
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c/">
<span class="md-ellipsis">
    Cs61c
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec06/">
<span class="md-ellipsis">
    Cs61c lec06
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec07/">
<span class="md-ellipsis">
    Cs61c lec07
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec08/">
<span class="md-ellipsis">
    Cs61c lec08
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec09/">
<span class="md-ellipsis">
    Cs61c lec09
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec10/">
<span class="md-ellipsis">
    Cs61c lec10
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec11/">
<span class="md-ellipsis">
    Cs61c lec11
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec12/">
<span class="md-ellipsis">
    Cs61c lec12
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec13/">
<span class="md-ellipsis">
    Cs61c lec13
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec14/">
<span class="md-ellipsis">
    Cs61c lec14
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/cs61c_lec15/">
<span class="md-ellipsis">
    Cs61c lec15
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cs61c/%E8%B7%B3%E8%BD%AC%E5%92%8C%E8%BF%94%E5%9B%9E%E7%9A%84%E5%87%BD%E6%95%B0/">
<span class="md-ellipsis">
    跳转和返回的函数
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
<span class="md-ellipsis">
    SLAM
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            SLAM
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../slam/%E8%A7%86%E8%A7%89SLAM%E5%8D%81%E5%9B%9B%E8%AE%B2/">
<span class="md-ellipsis">
    视觉SLAM十四讲
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
<span class="md-ellipsis">
    天元公学生存指南
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
            天元公学生存指南
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tygx_exp/eng_fht/">
<span class="md-ellipsis">
    英语经验分享
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tygx_exp/math_fht/">
<span class="md-ellipsis">
    数学经验分享
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tygx_exp/phy_fht/">
<span class="md-ellipsis">
    物理经验分享
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tygx_exp/tech_fht/">
<span class="md-ellipsis">
    技术经验分享
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tygx_exp/%E4%B8%80%E4%BA%9B%E8%B5%84%E6%BA%90/">
<span class="md-ellipsis">
    一些资源
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
<span class="md-ellipsis">
    动手学深度学习
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
            动手学深度学习
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Dive into Deep Learning
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Dive into Deep Learning
  </span>
</a>
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#1">
<span class="md-ellipsis">
      1 引言
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2">
<span class="md-ellipsis">
      2 预备知识
    </span>
</a>
<nav aria-label="2 预备知识" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#21">
<span class="md-ellipsis">
      2.1 数据操作
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#22">
<span class="md-ellipsis">
      2.2 数据预处理
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#23">
<span class="md-ellipsis">
      2.3 线性代数
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#24">
<span class="md-ellipsis">
      2.4 微积分
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#25-automatic-differentiation">
<span class="md-ellipsis">
      2.5 自动微分（automatic differentiation）
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#26">
<span class="md-ellipsis">
      2.6 概率
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3">
<span class="md-ellipsis">
      3 线性神经网络
    </span>
</a>
<nav aria-label="3 线性神经网络" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#31">
<span class="md-ellipsis">
      3.1 线性回归
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#32">
<span class="md-ellipsis">
      3.2 线性回归的从零开始实现
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#33">
<span class="md-ellipsis">
      3.3 线性回归的简洁实现
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#34-softmax">
<span class="md-ellipsis">
      3.4 softmax 回归
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#35">
<span class="md-ellipsis">
      3.5 图像分类数据集
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#36-softmax">
<span class="md-ellipsis">
      3.6 softmax 回归的从零开始实现
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#37-softmax">
<span class="md-ellipsis">
      3.7 softmax 回归的简洁实现
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
<span class="md-ellipsis">
    总结
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_7_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_7">
<span class="md-nav__icon md-icon"></span>
            总结
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../summary/202409-10/">
<span class="md-ellipsis">
    2024年9月10月总结
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../summary/2024summer_vacation/">
<span class="md-ellipsis">
    2024年高三-大一暑假总结
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#1">
<span class="md-ellipsis">
      1 引言
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2">
<span class="md-ellipsis">
      2 预备知识
    </span>
</a>
<nav aria-label="2 预备知识" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#21">
<span class="md-ellipsis">
      2.1 数据操作
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#22">
<span class="md-ellipsis">
      2.2 数据预处理
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#23">
<span class="md-ellipsis">
      2.3 线性代数
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#24">
<span class="md-ellipsis">
      2.4 微积分
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#25-automatic-differentiation">
<span class="md-ellipsis">
      2.5 自动微分（automatic differentiation）
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#26">
<span class="md-ellipsis">
      2.6 概率
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3">
<span class="md-ellipsis">
      3 线性神经网络
    </span>
</a>
<nav aria-label="3 线性神经网络" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#31">
<span class="md-ellipsis">
      3.1 线性回归
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#32">
<span class="md-ellipsis">
      3.2 线性回归的从零开始实现
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#33">
<span class="md-ellipsis">
      3.3 线性回归的简洁实现
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#34-softmax">
<span class="md-ellipsis">
      3.4 softmax 回归
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#35">
<span class="md-ellipsis">
      3.5 图像分类数据集
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#36-softmax">
<span class="md-ellipsis">
      3.6 softmax 回归的从零开始实现
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#37-softmax">
<span class="md-ellipsis">
      3.7 softmax 回归的简洁实现
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/WncFht/note/edit/master/docs/Dive into deep learning/Dive into Deep Learning.md" title="edit.link.title">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"></path></svg>
</a>
<h1 id="dive-into-deep-learning">Dive into Deep Learning<a class="headerlink" href="#dive-into-deep-learning" title="Permanent link">¶</a></h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p><span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"></path></svg></span> 约<span class="heti-skip"><span class="heti-spacing"> </span>3443<span class="heti-spacing"> </span></span>个字 <span class="twemoji"><svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"></path></svg></span> 预计阅读时间<span class="heti-skip"><span class="heti-spacing"> </span>11<span class="heti-spacing"> </span></span>分钟</p>
</div>
<h2 id="1"><span>1<span class="heti-spacing"> </span></span>引言<a class="headerlink" href="#1" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h2>
<h2 id="2"><span>2<span class="heti-spacing"> </span></span>预备知识<a class="headerlink" href="#2" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h2>
<h3 id="21"><span>2.1<span class="heti-spacing"> </span></span>数据操作<a class="headerlink" href="#21" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<ul>
<li>tensor</li>
<li>ndarray (MXNet)</li>
<li>Tensor (TensorFlow)</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span>
<span class="normal"><a href="#__codelineno-0-5">5</a></span>
<span class="normal"><a href="#__codelineno-0-6">6</a></span>
<span class="normal"><a href="#__codelineno-0-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a>x = torch.arrange(12)
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>x.shape
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>x.numel()
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>x.reshape(3, 4)
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>torch.zeros((2, 3, 4))
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>torch.ones((2, 3, 4))
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>torch.randn(3, 4)
</code></pre></div></td></tr></table></div>
<ul>
<li>elementwise：<ul>
<li>+</li>
<li>-</li>
<li>-</li>
<li>/</li>
<li>exp ()</li>
<li>==</li>
</ul>
</li>
<li>concatenate</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1">1</a></span>
<span class="normal"><a href="#__codelineno-1-2">2</a></span>
<span class="normal"><a href="#__codelineno-1-3">3</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a>torch.cat((X, Y), dim = 0) # 竖着加
<a id="__codelineno-1-2" name="__codelineno-1-2"></a>torch.cat((X, Y), dim = 1) # 横着加
<a id="__codelineno-1-3" name="__codelineno-1-3"></a>x.sum()
</code></pre></div></td></tr></table></div>
<ul>
<li>broadcasting mechanism<ul>
<li>复制拓展到形状一致后相加</li>
</ul>
</li>
<li>索引<span class="heti-skip"><span class="heti-spacing"> </span>+<span class="heti-spacing"> </span></span>切片</li>
<li>切片保持地址不变：节省内存</li>
<li>ndarry &lt;-&gt; Tensor</li>
<li>item ()</li>
</ul>
<h3 id="22"><span>2.2<span class="heti-spacing"> </span></span>数据预处理<a class="headerlink" href="#22" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<p>pandas</p>
<ul>
<li>read_csv ()</li>
<li>NaN<ul>
<li>fillna (inputs.mean ())</li>
<li>np.array (inputs. to_numpy (dtype = float))</li>
</ul>
</li>
</ul>
<h3 id="23"><span>2.3<span class="heti-spacing"> </span></span>线性代数<a class="headerlink" href="#23" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<ul>
<li>scalar</li>
<li>variable</li>
<li>space</li>
<li>element / component</li>
<li>dimension <ul>
<li>len ()</li>
<li>shape</li>
</ul>
</li>
<li>square matrix</li>
<li>transpose<ul>
<li>A.T</li>
</ul>
</li>
<li>symmetric matrix<ul>
<li>A == A.T</li>
</ul>
</li>
<li>channel</li>
<li>Hadamard product</li>
</ul>
<div class="arithmatex">\[
\begin{split}\mathbf{A} \odot \mathbf{B} =
\begin{bmatrix}
a_{11}  b_{11} &amp; a_{12}  b_{12} &amp; \dots  &amp; a_{1n}  b_{1n} \\
a_{21}  b_{21} &amp; a_{22}  b_{22} &amp; \dots  &amp; a_{2n}  b_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1}  b_{m1} &amp; a_{m2}  b_{m2} &amp; \dots  &amp; a_{mn}  b_{mn}
\end{bmatrix}.\end{split}
\]</div>
<ul>
<li><span>A.sum (axis = 0) #<span class="heti-spacing"> </span></span>竖着求和</li>
<li>A.sum (axis = [0, 1]) = A.sum ()</li>
<li>A.mean () = A.sum () / A.size ()</li>
<li>A.cumsum (axis = 0)</li>
<li>dot product<ul>
<li>torch.dot (x, y) = torch.sum (x * y)</li>
<li>weighted average</li>
</ul>
</li>
<li>matrix-vector product<ul>
<li>torch.mv (A, x)</li>
</ul>
</li>
<li>matrix-matric multiplication<ul>
<li>torch.mm (A, B)</li>
</ul>
</li>
<li>norm<ol>
<li><span class="arithmatex">\(f(\alpha \mathbf{x}) = |\alpha| f(\mathbf{x}).\)</span></li>
<li><span class="arithmatex">\((\mathbf{x} + \mathbf{y}) \leq f(\mathbf{x}) + f(\mathbf{y}).\)</span></li>
<li><span class="arithmatex">\(f(\mathbf{x}) \geq 0.\)</span></li>
</ol>
</li>
</ul>
<h3 id="24"><span>2.4<span class="heti-spacing"> </span></span>微积分<a class="headerlink" href="#24" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<h4 id="241"><span>2.4.1<span class="heti-spacing"> </span></span>导数和微分<a class="headerlink" href="#241" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<h4 id="242"><span>2.4.2<span class="heti-spacing"> </span></span>偏导数<a class="headerlink" href="#242" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<h4 id="243"><span>2.4.3<span class="heti-spacing"> </span></span>梯度<a class="headerlink" href="#243" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<div class="arithmatex">\[
\nabla_{\mathbf{x}} f(\mathbf{x}) = \bigg[\frac{\partial f(\mathbf{x})}{\partial x_1}, \frac{\partial f(\mathbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_n}\bigg]^\top,
\]</div>
<div class="arithmatex">\[
\nabla_{\mathbf{x}} \mathbf{A} \mathbf{x} = \mathbf{A}^\top
\]</div>
<div class="arithmatex">\[
\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A} = \mathbf{A}
\]</div>
<div class="arithmatex">\[
\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A} \mathbf{x} = (\mathbf{A} + \mathbf{A}^\top)\mathbf{x}
\]</div>
<div class="arithmatex">\[
\nabla_{\mathbf{x}} \|\mathbf{x} \|^2 = \nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{x} = 2\mathbf{x}
\]</div>
<div class="arithmatex">\[
\nabla_{\mathbf{X}} \|\mathbf{X} \|_F^2 = 2\mathbf{X}
\]</div>
<h4 id="244"><span>2.4.4<span class="heti-spacing"> </span></span>链式法则<a class="headerlink" href="#244" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<h4 id="245"><span>2.4.5<span class="heti-spacing"> </span></span>小结<a class="headerlink" href="#245" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<h3 id="25-automatic-differentiation"><span>2.5<span class="heti-spacing"> </span></span>自动微分（automatic differentiation）<a class="headerlink" href="#25-automatic-differentiation" title="Permanent link">¶</a></h3>
<ul>
<li>computational graph</li>
<li>backpropagate</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1">1</a></span>
<span class="normal"><a href="#__codelineno-2-2">2</a></span>
<span class="normal"><a href="#__codelineno-2-3">3</a></span>
<span class="normal"><a href="#__codelineno-2-4">4</a></span>
<span class="normal"><a href="#__codelineno-2-5">5</a></span>
<span class="normal"><a href="#__codelineno-2-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a>x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)
<a id="__codelineno-2-2" name="__codelineno-2-2"></a>x.grad  # 默认值是None
<a id="__codelineno-2-3" name="__codelineno-2-3"></a>y = 2 * torch.dot(x, x)
<a id="__codelineno-2-4" name="__codelineno-2-4"></a>y.backward()
<a id="__codelineno-2-5" name="__codelineno-2-5"></a>x.grad
<a id="__codelineno-2-6" name="__codelineno-2-6"></a>x.grad == 4 * x
</code></pre></div></td></tr></table></div>
<h4 id="251"><span>2.5.1<span class="heti-spacing"> </span></span>非标量变量的反向传播<a class="headerlink" href="#251" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1">1</a></span>
<span class="normal"><a href="#__codelineno-3-2">2</a></span>
<span class="normal"><a href="#__codelineno-3-3">3</a></span>
<span class="normal"><a href="#__codelineno-3-4">4</a></span>
<span class="normal"><a href="#__codelineno-3-5">5</a></span>
<span class="normal"><a href="#__codelineno-3-6">6</a></span>
<span class="normal"><a href="#__codelineno-3-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。
<a id="__codelineno-3-2" name="__codelineno-3-2"></a># 本例只想求偏导数的和，所以传递一个1的梯度是合适的
<a id="__codelineno-3-3" name="__codelineno-3-3"></a>x.grad.zero_()
<a id="__codelineno-3-4" name="__codelineno-3-4"></a>y = x * x
<a id="__codelineno-3-5" name="__codelineno-3-5"></a># 等价于y.backward(torch.ones(len(x)))
<a id="__codelineno-3-6" name="__codelineno-3-6"></a>y.sum().backward()
<a id="__codelineno-3-7" name="__codelineno-3-7"></a>x.grad
</code></pre></div></td></tr></table></div>
<h4 id="252"><span>2.5.2<span class="heti-spacing"> </span></span>分离计算<a class="headerlink" href="#252" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1">1</a></span>
<span class="normal"><a href="#__codelineno-4-2">2</a></span>
<span class="normal"><a href="#__codelineno-4-3">3</a></span>
<span class="normal"><a href="#__codelineno-4-4">4</a></span>
<span class="normal"><a href="#__codelineno-4-5">5</a></span>
<span class="normal"><a href="#__codelineno-4-6">6</a></span>
<span class="normal"><a href="#__codelineno-4-7">7</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a>x.grad.zero_()
<a id="__codelineno-4-2" name="__codelineno-4-2"></a>y = x * x
<a id="__codelineno-4-3" name="__codelineno-4-3"></a>u = y.detach()
<a id="__codelineno-4-4" name="__codelineno-4-4"></a>z = u * x
<a id="__codelineno-4-5" name="__codelineno-4-5"></a>
<a id="__codelineno-4-6" name="__codelineno-4-6"></a>z.sum().backward()
<a id="__codelineno-4-7" name="__codelineno-4-7"></a>x.grad == u
</code></pre></div></td></tr></table></div>
<h3 id="26"><span>2.6<span class="heti-spacing"> </span></span>概率<a class="headerlink" href="#26" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<h4 id="261"><span>2.6.1<span class="heti-spacing"> </span></span>基本概率论<a class="headerlink" href="#261" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>sampling</li>
<li>distribution</li>
<li>multinomial distribution</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1">1</a></span>
<span class="normal"><a href="#__codelineno-5-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a>fair_probs = torch.ones([6]) / 6
<a id="__codelineno-5-2" name="__codelineno-5-2"></a>multinomial.Multinomial(10, fair_probs).sample() # 多个样本
</code></pre></div></td></tr></table></div>
<h4 id="262"><span>2.6.2<span class="heti-spacing"> </span></span>处理多个随机变量<a class="headerlink" href="#262" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>joint probability</li>
<li>conditional probability</li>
<li>Bayes’ theorem</li>
</ul>
<div class="arithmatex">\[
P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}. 
\]</div>
<ul>
<li>其中<span class="heti-skip"><span class="heti-spacing"> </span>P (A, B)<span class="heti-spacing"> </span></span>是一个联合分布<span><span class="heti-spacing"> </span>(joint distribution)</span>， P (A∣<span>B)<span class="heti-spacing"> </span></span>是一个条件分布<span><span class="heti-spacing"> </span>(conditional distribution)</span></li>
<li>marginalization<ul>
<li>marginal probability</li>
<li>marginal distribution</li>
</ul>
</li>
<li>conditionally independent</li>
</ul>
<p>$$
 P(A, B \mid C) = P(A \mid C)P(B \mid C) 
$$</p>
<div class="arithmatex">\[
A \perp B \mid C 
\]</div>
<ul>
<li>expectation</li>
</ul>
<div class="arithmatex">\[
E[X] = \sum_{x} x P(X = x). 
\]</div>
<div class="arithmatex">\[
E_{x \sim P}[f(x)] = \sum_x f(x) P(x). 
\]</div>
<ul>
<li>standard deviation</li>
</ul>
<div class="arithmatex">\[
\mathrm{Var}[X] = E\left[(X - E[X])^2\right] =
E[X^2] - E[X]^2. 
\]</div>
<div class="arithmatex">\[
\mathrm{Var}[f(x)] = E\left[\left(f(x) - E[f(x)]\right)^2\right]. 
\]</div>
<h2 id="3"><span>3<span class="heti-spacing"> </span></span>线性神经网络<a class="headerlink" href="#3" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h2>
<h3 id="31"><span>3.1<span class="heti-spacing"> </span></span>线性回归<a class="headerlink" href="#31" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<h4 id="311"><span>3.1.1<span class="heti-spacing"> </span></span>线性回归的基本元素<a class="headerlink" href="#311" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>regression</li>
<li>prediction / inference</li>
<li>training set</li>
<li>sample / data point / data instance</li>
<li>label / target</li>
<li>feature / covariate</li>
</ul>
<div class="arithmatex">\[
\mathrm{price} = w_{\mathrm{area}} \cdot \mathrm{area} + w_{\mathrm{age}} \cdot \mathrm{age} + b. 
\]</div>
<ul>
<li>weight</li>
<li>bias / offset / intercept</li>
<li>affine transformation<ul>
<li>linear transformation</li>
<li>translation</li>
</ul>
</li>
<li>model parameters</li>
<li>loss function</li>
</ul>
<div class="arithmatex">\[
l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2.
\]</div>
<div class="arithmatex">\[
L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2.
\]</div>
<div class="arithmatex">\[
\mathbf{w}^*, b^* = \operatorname*{argmin}_{\mathbf{w}, b}\  L(\mathbf{w}, b).
\]</div>
<div class="arithmatex">\[
\mathbf{w}^{*} = (\mathbf X^\top \mathbf X)^{-1}\mathbf X^\top \mathbf{y}.
\]</div>
<ul>
<li>analytical solution</li>
<li>gradient descent<ul>
<li>minibatch stochastic gradient descent</li>
</ul>
</li>
</ul>
<div class="arithmatex">\[
(\mathbf{w},b) \leftarrow (\mathbf{w},b) - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{(\mathbf{w},b)} l^{(i)}(\mathbf{w},b).
\]</div>
<ol>
<li>初始化模型参数的值，如随机初始化</li>
<li>从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤
- hyperparameter<ul>
<li><span class="arithmatex">\(|\mathcal{B}|\)</span>: batch size</li>
<li><span class="arithmatex">\(\eta\)</span>: learning rate</li>
<li>hyperparameter tuning</li>
<li>validationg dataset</li>
<li>generalization</li>
</ul>
</li>
</ol>
<h4 id="312"><span>3.1.2<span class="heti-spacing"> </span></span>矢量化加速<a class="headerlink" href="#312" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>矢量化代码</li>
</ul>
<h4 id="313"><span>3.1.3<span class="heti-spacing"> </span></span>正态分布与平方损失<a class="headerlink" href="#313" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>normal distribution / Gaussian distribution</li>
</ul>
<div class="arithmatex">\[
p(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2 \sigma^2} (x - \mu)^2\right).
\]</div>
<div class="arithmatex">\[
y = \mathbf{w}^\top \mathbf{x} + b + \epsilon,
\]</div>
<p>其中<span class="heti-skip"><span class="heti-spacing"> </span><span class="arithmatex">\(\epsilon \sim \mathcal{N}(0, \sigma^2)\)</span>.<span class="heti-spacing"> </span></span>因此<span class="heti-skip"><span class="heti-spacing"> </span>y<span class="heti-spacing"> </span></span>的<span><span class="heti-spacing"> </span>likelihood:</span></p>
<div class="arithmatex">\[
P(y \mid \mathbf{x}) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2 \sigma^2} (y - \mathbf{w}^\top \mathbf{x} - b)^2\right).
\]</div>
<div class="arithmatex">\[
P(\mathbf y \mid \mathbf X) = \prod_{i=1}^{n} p(y^{(i)}|\mathbf{x}^{(i)}).
\]</div>
<div class="arithmatex">\[
-\log P(\mathbf y \mid \mathbf X) = \sum_{i=1}^n \frac{1}{2} \log(2 \pi \sigma^2) + \frac{1}{2 \sigma^2} \left(y^{(i)} - \mathbf{w}^\top \mathbf{x}^{(i)} - b\right)^2.
\]</div>
<h4 id="314"><span>3.1.4<span class="heti-spacing"> </span></span>从线性回归到神经网络<a class="headerlink" href="#314" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>feature dimensionality</li>
<li>fully-connected layer / dense layer</li>
</ul>
<h3 id="32"><span>3.2<span class="heti-spacing"> </span></span>线性回归的从零开始实现<a class="headerlink" href="#32" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-6-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-6-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-6-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-6-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-6-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-6-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-6-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-6-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-6-10">10</a></span>
<span class="normal"><a href="#__codelineno-6-11">11</a></span>
<span class="normal"><a href="#__codelineno-6-12">12</a></span>
<span class="normal"><a href="#__codelineno-6-13">13</a></span>
<span class="normal"><a href="#__codelineno-6-14">14</a></span>
<span class="normal"><a href="#__codelineno-6-15">15</a></span>
<span class="normal"><a href="#__codelineno-6-16">16</a></span>
<span class="normal"><a href="#__codelineno-6-17">17</a></span>
<span class="normal"><a href="#__codelineno-6-18">18</a></span>
<span class="normal"><a href="#__codelineno-6-19">19</a></span>
<span class="normal"><a href="#__codelineno-6-20">20</a></span>
<span class="normal"><a href="#__codelineno-6-21">21</a></span>
<span class="normal"><a href="#__codelineno-6-22">22</a></span>
<span class="normal"><a href="#__codelineno-6-23">23</a></span>
<span class="normal"><a href="#__codelineno-6-24">24</a></span>
<span class="normal"><a href="#__codelineno-6-25">25</a></span>
<span class="normal"><a href="#__codelineno-6-26">26</a></span>
<span class="normal"><a href="#__codelineno-6-27">27</a></span>
<span class="normal"><a href="#__codelineno-6-28">28</a></span>
<span class="normal"><a href="#__codelineno-6-29">29</a></span>
<span class="normal"><a href="#__codelineno-6-30">30</a></span>
<span class="normal"><a href="#__codelineno-6-31">31</a></span>
<span class="normal"><a href="#__codelineno-6-32">32</a></span>
<span class="normal"><a href="#__codelineno-6-33">33</a></span>
<span class="normal"><a href="#__codelineno-6-34">34</a></span>
<span class="normal"><a href="#__codelineno-6-35">35</a></span>
<span class="normal"><a href="#__codelineno-6-36">36</a></span>
<span class="normal"><a href="#__codelineno-6-37">37</a></span>
<span class="normal"><a href="#__codelineno-6-38">38</a></span>
<span class="normal"><a href="#__codelineno-6-39">39</a></span>
<span class="normal"><a href="#__codelineno-6-40">40</a></span>
<span class="normal"><a href="#__codelineno-6-41">41</a></span>
<span class="normal"><a href="#__codelineno-6-42">42</a></span>
<span class="normal"><a href="#__codelineno-6-43">43</a></span>
<span class="normal"><a href="#__codelineno-6-44">44</a></span>
<span class="normal"><a href="#__codelineno-6-45">45</a></span>
<span class="normal"><a href="#__codelineno-6-46">46</a></span>
<span class="normal"><a href="#__codelineno-6-47">47</a></span>
<span class="normal"><a href="#__codelineno-6-48">48</a></span>
<span class="normal"><a href="#__codelineno-6-49">49</a></span>
<span class="normal"><a href="#__codelineno-6-50">50</a></span>
<span class="normal"><a href="#__codelineno-6-51">51</a></span>
<span class="normal"><a href="#__codelineno-6-52">52</a></span>
<span class="normal"><a href="#__codelineno-6-53">53</a></span>
<span class="normal"><a href="#__codelineno-6-54">54</a></span>
<span class="normal"><a href="#__codelineno-6-55">55</a></span>
<span class="normal"><a href="#__codelineno-6-56">56</a></span>
<span class="normal"><a href="#__codelineno-6-57">57</a></span>
<span class="normal"><a href="#__codelineno-6-58">58</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1"></a>%matplotlib inline
<a id="__codelineno-6-2" name="__codelineno-6-2"></a>import random
<a id="__codelineno-6-3" name="__codelineno-6-3"></a>import torch
<a id="__codelineno-6-4" name="__codelineno-6-4"></a>from d2l import torch as d2l
<a id="__codelineno-6-5" name="__codelineno-6-5"></a>def synthetic_data(w, b, num_examples):  #@save
<a id="__codelineno-6-6" name="__codelineno-6-6"></a>    """生成y=Xw+b+噪声"""
<a id="__codelineno-6-7" name="__codelineno-6-7"></a>    X = torch.normal(0, 1, (num_examples, len(w)))
<a id="__codelineno-6-8" name="__codelineno-6-8"></a>    y = torch.matmul(X, w) + b
<a id="__codelineno-6-9" name="__codelineno-6-9"></a>    y += torch.normal(0, 0.01, y.shape)
<a id="__codelineno-6-10" name="__codelineno-6-10"></a>    return X, y.reshape((-1, 1))
<a id="__codelineno-6-11" name="__codelineno-6-11"></a>
<a id="__codelineno-6-12" name="__codelineno-6-12"></a>true_w = torch.tensor([2, -3.4])
<a id="__codelineno-6-13" name="__codelineno-6-13"></a>true_b = 4.2
<a id="__codelineno-6-14" name="__codelineno-6-14"></a>features, labels = synthetic_data(true_w, true_b, 1000)
<a id="__codelineno-6-15" name="__codelineno-6-15"></a>
<a id="__codelineno-6-16" name="__codelineno-6-16"></a>def data_iter(batch_size, features, labels):
<a id="__codelineno-6-17" name="__codelineno-6-17"></a>    num_examples = len(features)
<a id="__codelineno-6-18" name="__codelineno-6-18"></a>    indices = list(range(num_examples))
<a id="__codelineno-6-19" name="__codelineno-6-19"></a>    # 这些样本是随机读取的，没有特定的顺序
<a id="__codelineno-6-20" name="__codelineno-6-20"></a>    random.shuffle(indices)
<a id="__codelineno-6-21" name="__codelineno-6-21"></a>    for i in range(0, num_examples, batch_size):
<a id="__codelineno-6-22" name="__codelineno-6-22"></a>        batch_indices = torch.tensor(
<a id="__codelineno-6-23" name="__codelineno-6-23"></a>            indices[i: min(i + batch_size, num_examples)])
<a id="__codelineno-6-24" name="__codelineno-6-24"></a>        yield features[batch_indices], labels[batch_indices]
<a id="__codelineno-6-25" name="__codelineno-6-25"></a>
<a id="__codelineno-6-26" name="__codelineno-6-26"></a>w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
<a id="__codelineno-6-27" name="__codelineno-6-27"></a>b = torch.zeros(1, requires_grad=True)
<a id="__codelineno-6-28" name="__codelineno-6-28"></a>
<a id="__codelineno-6-29" name="__codelineno-6-29"></a>def linreg(X, w, b):  #@save
<a id="__codelineno-6-30" name="__codelineno-6-30"></a>    """线性回归模型"""
<a id="__codelineno-6-31" name="__codelineno-6-31"></a>    return torch.matmul(X, w) + b
<a id="__codelineno-6-32" name="__codelineno-6-32"></a>
<a id="__codelineno-6-33" name="__codelineno-6-33"></a>def squared_loss(y_hat, y):  #@save
<a id="__codelineno-6-34" name="__codelineno-6-34"></a>    """均方损失"""
<a id="__codelineno-6-35" name="__codelineno-6-35"></a>    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
<a id="__codelineno-6-36" name="__codelineno-6-36"></a>
<a id="__codelineno-6-37" name="__codelineno-6-37"></a>def sgd(params, lr, batch_size):  #@save
<a id="__codelineno-6-38" name="__codelineno-6-38"></a>    """小批量随机梯度下降"""
<a id="__codelineno-6-39" name="__codelineno-6-39"></a>    with torch.no_grad():
<a id="__codelineno-6-40" name="__codelineno-6-40"></a>        for param in params:
<a id="__codelineno-6-41" name="__codelineno-6-41"></a>            param -= lr * param.grad / batch_size
<a id="__codelineno-6-42" name="__codelineno-6-42"></a>            param.grad.zero_()
<a id="__codelineno-6-43" name="__codelineno-6-43"></a>
<a id="__codelineno-6-44" name="__codelineno-6-44"></a>lr = 0.03
<a id="__codelineno-6-45" name="__codelineno-6-45"></a>num_epochs = 3
<a id="__codelineno-6-46" name="__codelineno-6-46"></a>net = linreg
<a id="__codelineno-6-47" name="__codelineno-6-47"></a>loss = squared_loss
<a id="__codelineno-6-48" name="__codelineno-6-48"></a>
<a id="__codelineno-6-49" name="__codelineno-6-49"></a>for epoch in range(num_epochs):
<a id="__codelineno-6-50" name="__codelineno-6-50"></a>    for X, y in data_iter(batch_size, features, labels):
<a id="__codelineno-6-51" name="__codelineno-6-51"></a>        l = loss(net(X, w, b), y)  # X和y的小批量损失
<a id="__codelineno-6-52" name="__codelineno-6-52"></a>        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，
<a id="__codelineno-6-53" name="__codelineno-6-53"></a>        # 并以此计算关于[w,b]的梯度
<a id="__codelineno-6-54" name="__codelineno-6-54"></a>        l.sum().backward()
<a id="__codelineno-6-55" name="__codelineno-6-55"></a>        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数
<a id="__codelineno-6-56" name="__codelineno-6-56"></a>    with torch.no_grad():
<a id="__codelineno-6-57" name="__codelineno-6-57"></a>        train_l = loss(net(features, w, b), labels)
<a id="__codelineno-6-58" name="__codelineno-6-58"></a>        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
</code></pre></div></td></tr></table></div>
<h3 id="33"><span>3.3<span class="heti-spacing"> </span></span>线性回归的简洁实现<a class="headerlink" href="#33" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-7-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-7-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-7-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-7-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-7-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-7-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-7-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-7-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-7-10">10</a></span>
<span class="normal"><a href="#__codelineno-7-11">11</a></span>
<span class="normal"><a href="#__codelineno-7-12">12</a></span>
<span class="normal"><a href="#__codelineno-7-13">13</a></span>
<span class="normal"><a href="#__codelineno-7-14">14</a></span>
<span class="normal"><a href="#__codelineno-7-15">15</a></span>
<span class="normal"><a href="#__codelineno-7-16">16</a></span>
<span class="normal"><a href="#__codelineno-7-17">17</a></span>
<span class="normal"><a href="#__codelineno-7-18">18</a></span>
<span class="normal"><a href="#__codelineno-7-19">19</a></span>
<span class="normal"><a href="#__codelineno-7-20">20</a></span>
<span class="normal"><a href="#__codelineno-7-21">21</a></span>
<span class="normal"><a href="#__codelineno-7-22">22</a></span>
<span class="normal"><a href="#__codelineno-7-23">23</a></span>
<span class="normal"><a href="#__codelineno-7-24">24</a></span>
<span class="normal"><a href="#__codelineno-7-25">25</a></span>
<span class="normal"><a href="#__codelineno-7-26">26</a></span>
<span class="normal"><a href="#__codelineno-7-27">27</a></span>
<span class="normal"><a href="#__codelineno-7-28">28</a></span>
<span class="normal"><a href="#__codelineno-7-29">29</a></span>
<span class="normal"><a href="#__codelineno-7-30">30</a></span>
<span class="normal"><a href="#__codelineno-7-31">31</a></span>
<span class="normal"><a href="#__codelineno-7-32">32</a></span>
<span class="normal"><a href="#__codelineno-7-33">33</a></span>
<span class="normal"><a href="#__codelineno-7-34">34</a></span>
<span class="normal"><a href="#__codelineno-7-35">35</a></span>
<span class="normal"><a href="#__codelineno-7-36">36</a></span>
<span class="normal"><a href="#__codelineno-7-37">37</a></span>
<span class="normal"><a href="#__codelineno-7-38">38</a></span>
<span class="normal"><a href="#__codelineno-7-39">39</a></span>
<span class="normal"><a href="#__codelineno-7-40">40</a></span>
<span class="normal"><a href="#__codelineno-7-41">41</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a>import numpy as np
<a id="__codelineno-7-2" name="__codelineno-7-2"></a>import torch
<a id="__codelineno-7-3" name="__codelineno-7-3"></a>from torch.utils import data
<a id="__codelineno-7-4" name="__codelineno-7-4"></a>from d2l import torch as d2l
<a id="__codelineno-7-5" name="__codelineno-7-5"></a>
<a id="__codelineno-7-6" name="__codelineno-7-6"></a>true_w = torch.tensor([2, -3.4])
<a id="__codelineno-7-7" name="__codelineno-7-7"></a>true_b = 4.2
<a id="__codelineno-7-8" name="__codelineno-7-8"></a>features, labels = d2l.synthetic_data(true_w, true_b, 1000) # 生成数据集
<a id="__codelineno-7-9" name="__codelineno-7-9"></a>
<a id="__codelineno-7-10" name="__codelineno-7-10"></a>def load_array(data_arrays, batch_size, is_train=True):  #@save
<a id="__codelineno-7-11" name="__codelineno-7-11"></a>    """构造一个PyTorch数据迭代器"""
<a id="__codelineno-7-12" name="__codelineno-7-12"></a>    dataset = data.TensorDataset(*data_arrays)
<a id="__codelineno-7-13" name="__codelineno-7-13"></a>    return data.DataLoader(dataset, batch_size, shuffle=is_train)
<a id="__codelineno-7-14" name="__codelineno-7-14"></a>
<a id="__codelineno-7-15" name="__codelineno-7-15"></a>batch_size = 10
<a id="__codelineno-7-16" name="__codelineno-7-16"></a>data_iter = load_array((features, labels), batch_size) # 读取数据集
<a id="__codelineno-7-17" name="__codelineno-7-17"></a>
<a id="__codelineno-7-18" name="__codelineno-7-18"></a># nn是神经网络的缩写
<a id="__codelineno-7-19" name="__codelineno-7-19"></a>from torch import nn
<a id="__codelineno-7-20" name="__codelineno-7-20"></a>
<a id="__codelineno-7-21" name="__codelineno-7-21"></a>net = nn.Sequential(nn.Linear(2, 1)) # 定义模型 （输入，输出）特征形状
<a id="__codelineno-7-22" name="__codelineno-7-22"></a>net[0].weight.data.normal_(0, 0.01)
<a id="__codelineno-7-23" name="__codelineno-7-23"></a>net[0].bias.data.fill_(0) # 初始化模型参数
<a id="__codelineno-7-24" name="__codelineno-7-24"></a>loss = nn.MSELoss() # 定义损失函数
<a id="__codelineno-7-25" name="__codelineno-7-25"></a>trainer = torch.optim.SGD(net.parameters(), lr=0.03) # 定义优化算法
<a id="__codelineno-7-26" name="__codelineno-7-26"></a>
<a id="__codelineno-7-27" name="__codelineno-7-27"></a># 训练
<a id="__codelineno-7-28" name="__codelineno-7-28"></a>num_epochs = 3
<a id="__codelineno-7-29" name="__codelineno-7-29"></a>for epoch in range(num_epochs):
<a id="__codelineno-7-30" name="__codelineno-7-30"></a>    for X, y in data_iter:
<a id="__codelineno-7-31" name="__codelineno-7-31"></a>        l = loss(net(X) ,y)
<a id="__codelineno-7-32" name="__codelineno-7-32"></a>        trainer.zero_grad()
<a id="__codelineno-7-33" name="__codelineno-7-33"></a>        l.backward()
<a id="__codelineno-7-34" name="__codelineno-7-34"></a>        trainer.step()
<a id="__codelineno-7-35" name="__codelineno-7-35"></a>    l = loss(net(features), labels)
<a id="__codelineno-7-36" name="__codelineno-7-36"></a>    print(f'epoch {epoch + 1}, loss {l:f}')
<a id="__codelineno-7-37" name="__codelineno-7-37"></a>
<a id="__codelineno-7-38" name="__codelineno-7-38"></a>w = net[0].weight.data
<a id="__codelineno-7-39" name="__codelineno-7-39"></a>print('w的估计误差：', true_w - w.reshape(true_w.shape))
<a id="__codelineno-7-40" name="__codelineno-7-40"></a>b = net[0].bias.data
<a id="__codelineno-7-41" name="__codelineno-7-41"></a>print('b的估计误差：', true_b - b)
</code></pre></div></td></tr></table></div>
<h3 id="34-softmax"><span>3.4 softmax<span class="heti-spacing"> </span></span>回归<a class="headerlink" href="#34-softmax" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<h4 id="341"><span>3.4.1<span class="heti-spacing"> </span></span>分类问题<a class="headerlink" href="#341" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>one-hot encoding</li>
</ul>
<div class="arithmatex">\[
y \in \{(1, 0, 0), (0, 1, 0), (0, 0, 1)\}.
\]</div>
<h4 id="342"><span>3.4.2<span class="heti-spacing"> </span></span>网络架构<a class="headerlink" href="#342" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>affine function</li>
<li>logit</li>
</ul>
<div class="arithmatex">\[
\begin{split}\begin{aligned}
o_1 &amp;= x_1 w_{11} + x_2 w_{12} + x_3 w_{13} + x_4 w_{14} + b_1,\\
o_2 &amp;= x_1 w_{21} + x_2 w_{22} + x_3 w_{23} + x_4 w_{24} + b_2,\\
o_3 &amp;= x_1 w_{31} + x_2 w_{32} + x_3 w_{33} + x_4 w_{34} + b_3.
\end{aligned}\end{split}
\]</div>
<h4 id="343"><span>3.4.3<span class="heti-spacing"> </span></span>全连接层的参数开销<a class="headerlink" href="#343" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<p>不知道是什么东西</p>
<h4 id="344-softmax"><span>3.4.4 softmax<span class="heti-spacing"> </span></span>运算<a class="headerlink" href="#344-softmax" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>calibration</li>
<li>choice model</li>
</ul>
<div class="arithmatex">\[
\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o})\quad \text{其中}\quad \hat{y}_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}
\]</div>
<div class="arithmatex">\[
\operatorname*{argmax}_j \hat y_j = \operatorname*{argmax}_j o_j.
\]</div>
<ul>
<li>linear model</li>
</ul>
<h4 id="345"><span>3.4.5<span class="heti-spacing"> </span></span>小批样本的矢量化<a class="headerlink" href="#345" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<div class="arithmatex">\[
\begin{split}\begin{aligned} \mathbf{O} &amp;= \mathbf{X} \mathbf{W} + \mathbf{b}, \\ \hat{\mathbf{Y}} &amp; = \mathrm{softmax}(\mathbf{O}). \end{aligned}\end{split}
\]</div>
<h4 id="346"><span>3.4.6<span class="heti-spacing"> </span></span>损失函数<a class="headerlink" href="#346" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<div class="arithmatex">\[
P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}).
\]</div>
<div class="arithmatex">\[
-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}),
\]</div>
<div class="arithmatex">\[
l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j.
\]</div>
<ul>
<li>cross-entropy loss</li>
</ul>
<div class="arithmatex">\[
\begin{split}\begin{aligned}
l(\mathbf{y}, \hat{\mathbf{y}}) &amp;=  - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\
&amp;= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j\\
&amp;= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j.
\end{aligned}\end{split}
\]</div>
<div class="arithmatex">\[
\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \mathrm{softmax}(\mathbf{o})_j - y_j.
\]</div>
<h4 id="347"><span>3.4.7<span class="heti-spacing"> </span></span>信息论基础<a class="headerlink" href="#347" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>information theory</li>
<li>entropy</li>
</ul>
<div class="arithmatex">\[
H[P] = \sum_j - P(j) \log P(j).
\]</div>
<h4 id="348"><span>3.4.8<span class="heti-spacing"> </span></span>模型预测和评估<a class="headerlink" href="#348" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h4>
<ul>
<li>accuracy</li>
</ul>
<h3 id="35"><span>3.5<span class="heti-spacing"> </span></span>图像分类数据集<a class="headerlink" href="#35" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-8-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-8-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-8-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-8-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-8-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-8-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-8-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-8-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-8-10">10</a></span>
<span class="normal"><a href="#__codelineno-8-11">11</a></span>
<span class="normal"><a href="#__codelineno-8-12">12</a></span>
<span class="normal"><a href="#__codelineno-8-13">13</a></span>
<span class="normal"><a href="#__codelineno-8-14">14</a></span>
<span class="normal"><a href="#__codelineno-8-15">15</a></span>
<span class="normal"><a href="#__codelineno-8-16">16</a></span>
<span class="normal"><a href="#__codelineno-8-17">17</a></span>
<span class="normal"><a href="#__codelineno-8-18">18</a></span>
<span class="normal"><a href="#__codelineno-8-19">19</a></span>
<span class="normal"><a href="#__codelineno-8-20">20</a></span>
<span class="normal"><a href="#__codelineno-8-21">21</a></span>
<span class="normal"><a href="#__codelineno-8-22">22</a></span>
<span class="normal"><a href="#__codelineno-8-23">23</a></span>
<span class="normal"><a href="#__codelineno-8-24">24</a></span>
<span class="normal"><a href="#__codelineno-8-25">25</a></span>
<span class="normal"><a href="#__codelineno-8-26">26</a></span>
<span class="normal"><a href="#__codelineno-8-27">27</a></span>
<span class="normal"><a href="#__codelineno-8-28">28</a></span>
<span class="normal"><a href="#__codelineno-8-29">29</a></span>
<span class="normal"><a href="#__codelineno-8-30">30</a></span>
<span class="normal"><a href="#__codelineno-8-31">31</a></span>
<span class="normal"><a href="#__codelineno-8-32">32</a></span>
<span class="normal"><a href="#__codelineno-8-33">33</a></span>
<span class="normal"><a href="#__codelineno-8-34">34</a></span>
<span class="normal"><a href="#__codelineno-8-35">35</a></span>
<span class="normal"><a href="#__codelineno-8-36">36</a></span>
<span class="normal"><a href="#__codelineno-8-37">37</a></span>
<span class="normal"><a href="#__codelineno-8-38">38</a></span>
<span class="normal"><a href="#__codelineno-8-39">39</a></span>
<span class="normal"><a href="#__codelineno-8-40">40</a></span>
<span class="normal"><a href="#__codelineno-8-41">41</a></span>
<span class="normal"><a href="#__codelineno-8-42">42</a></span>
<span class="normal"><a href="#__codelineno-8-43">43</a></span>
<span class="normal"><a href="#__codelineno-8-44">44</a></span>
<span class="normal"><a href="#__codelineno-8-45">45</a></span>
<span class="normal"><a href="#__codelineno-8-46">46</a></span>
<span class="normal"><a href="#__codelineno-8-47">47</a></span>
<span class="normal"><a href="#__codelineno-8-48">48</a></span>
<span class="normal"><a href="#__codelineno-8-49">49</a></span>
<span class="normal"><a href="#__codelineno-8-50">50</a></span>
<span class="normal"><a href="#__codelineno-8-51">51</a></span>
<span class="normal"><a href="#__codelineno-8-52">52</a></span>
<span class="normal"><a href="#__codelineno-8-53">53</a></span>
<span class="normal"><a href="#__codelineno-8-54">54</a></span>
<span class="normal"><a href="#__codelineno-8-55">55</a></span>
<span class="normal"><a href="#__codelineno-8-56">56</a></span>
<span class="normal"><a href="#__codelineno-8-57">57</a></span>
<span class="normal"><a href="#__codelineno-8-58">58</a></span>
<span class="normal"><a href="#__codelineno-8-59">59</a></span>
<span class="normal"><a href="#__codelineno-8-60">60</a></span>
<span class="normal"><a href="#__codelineno-8-61">61</a></span>
<span class="normal"><a href="#__codelineno-8-62">62</a></span>
<span class="normal"><a href="#__codelineno-8-63">63</a></span>
<span class="normal"><a href="#__codelineno-8-64">64</a></span>
<span class="normal"><a href="#__codelineno-8-65">65</a></span>
<span class="normal"><a href="#__codelineno-8-66">66</a></span>
<span class="normal"><a href="#__codelineno-8-67">67</a></span>
<span class="normal"><a href="#__codelineno-8-68">68</a></span>
<span class="normal"><a href="#__codelineno-8-69">69</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1"></a>%matplotlib inline
<a id="__codelineno-8-2" name="__codelineno-8-2"></a>import torch
<a id="__codelineno-8-3" name="__codelineno-8-3"></a>import torchvision
<a id="__codelineno-8-4" name="__codelineno-8-4"></a>from torch.utils import data
<a id="__codelineno-8-5" name="__codelineno-8-5"></a>from torchvision import transforms
<a id="__codelineno-8-6" name="__codelineno-8-6"></a>from d2l import torch as d2l
<a id="__codelineno-8-7" name="__codelineno-8-7"></a>
<a id="__codelineno-8-8" name="__codelineno-8-8"></a>d2l.use_svg_display()
<a id="__codelineno-8-9" name="__codelineno-8-9"></a>
<a id="__codelineno-8-10" name="__codelineno-8-10"></a># 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，
<a id="__codelineno-8-11" name="__codelineno-8-11"></a># 并除以255使得所有像素的数值均在0～1之间
<a id="__codelineno-8-12" name="__codelineno-8-12"></a>trans = transforms.ToTensor()
<a id="__codelineno-8-13" name="__codelineno-8-13"></a>mnist_train = torchvision.datasets.FashionMNIST(
<a id="__codelineno-8-14" name="__codelineno-8-14"></a>    root="../data", train=True, transform=trans, download=True)
<a id="__codelineno-8-15" name="__codelineno-8-15"></a>mnist_test = torchvision.datasets.FashionMNIST(
<a id="__codelineno-8-16" name="__codelineno-8-16"></a>    root="../data", train=False, transform=trans, download=True)
<a id="__codelineno-8-17" name="__codelineno-8-17"></a>
<a id="__codelineno-8-18" name="__codelineno-8-18"></a>def get_fashion_mnist_labels(labels):  #@save
<a id="__codelineno-8-19" name="__codelineno-8-19"></a>    """返回Fashion-MNIST数据集的文本标签"""
<a id="__codelineno-8-20" name="__codelineno-8-20"></a>    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
<a id="__codelineno-8-21" name="__codelineno-8-21"></a>                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
<a id="__codelineno-8-22" name="__codelineno-8-22"></a>    return [text_labels[int(i)] for i in labels]
<a id="__codelineno-8-23" name="__codelineno-8-23"></a>
<a id="__codelineno-8-24" name="__codelineno-8-24"></a>def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
<a id="__codelineno-8-25" name="__codelineno-8-25"></a>    """绘制图像列表"""
<a id="__codelineno-8-26" name="__codelineno-8-26"></a>    figsize = (num_cols * scale, num_rows * scale)
<a id="__codelineno-8-27" name="__codelineno-8-27"></a>    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
<a id="__codelineno-8-28" name="__codelineno-8-28"></a>    axes = axes.flatten()
<a id="__codelineno-8-29" name="__codelineno-8-29"></a>    for i, (ax, img) in enumerate(zip(axes, imgs)):
<a id="__codelineno-8-30" name="__codelineno-8-30"></a>        if torch.is_tensor(img):
<a id="__codelineno-8-31" name="__codelineno-8-31"></a>            # 图片张量
<a id="__codelineno-8-32" name="__codelineno-8-32"></a>            ax.imshow(img.numpy())
<a id="__codelineno-8-33" name="__codelineno-8-33"></a>        else:
<a id="__codelineno-8-34" name="__codelineno-8-34"></a>            # PIL图片
<a id="__codelineno-8-35" name="__codelineno-8-35"></a>            ax.imshow(img)
<a id="__codelineno-8-36" name="__codelineno-8-36"></a>        ax.axes.get_xaxis().set_visible(False)
<a id="__codelineno-8-37" name="__codelineno-8-37"></a>        ax.axes.get_yaxis().set_visible(False)
<a id="__codelineno-8-38" name="__codelineno-8-38"></a>        if titles:
<a id="__codelineno-8-39" name="__codelineno-8-39"></a>            ax.set_title(titles[i])
<a id="__codelineno-8-40" name="__codelineno-8-40"></a>    return axes
<a id="__codelineno-8-41" name="__codelineno-8-41"></a>
<a id="__codelineno-8-42" name="__codelineno-8-42"></a>batch_size = 256
<a id="__codelineno-8-43" name="__codelineno-8-43"></a>
<a id="__codelineno-8-44" name="__codelineno-8-44"></a>def get_dataloader_workers():  #@save
<a id="__codelineno-8-45" name="__codelineno-8-45"></a>    """使用4个进程来读取数据"""
<a id="__codelineno-8-46" name="__codelineno-8-46"></a>    return 4
<a id="__codelineno-8-47" name="__codelineno-8-47"></a>
<a id="__codelineno-8-48" name="__codelineno-8-48"></a>train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,
<a id="__codelineno-8-49" name="__codelineno-8-49"></a>                             num_workers=get_dataloader_workers())
<a id="__codelineno-8-50" name="__codelineno-8-50"></a>
<a id="__codelineno-8-51" name="__codelineno-8-51"></a>def load_data_fashion_mnist(batch_size, resize=None):  #@save
<a id="__codelineno-8-52" name="__codelineno-8-52"></a>    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
<a id="__codelineno-8-53" name="__codelineno-8-53"></a>    trans = [transforms.ToTensor()]
<a id="__codelineno-8-54" name="__codelineno-8-54"></a>    if resize:
<a id="__codelineno-8-55" name="__codelineno-8-55"></a>        trans.insert(0, transforms.Resize(resize))
<a id="__codelineno-8-56" name="__codelineno-8-56"></a>    trans = transforms.Compose(trans)
<a id="__codelineno-8-57" name="__codelineno-8-57"></a>    mnist_train = torchvision.datasets.FashionMNIST(
<a id="__codelineno-8-58" name="__codelineno-8-58"></a>        root="../data", train=True, transform=trans, download=True)
<a id="__codelineno-8-59" name="__codelineno-8-59"></a>    mnist_test = torchvision.datasets.FashionMNIST(
<a id="__codelineno-8-60" name="__codelineno-8-60"></a>        root="../data", train=False, transform=trans, download=True)
<a id="__codelineno-8-61" name="__codelineno-8-61"></a>    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
<a id="__codelineno-8-62" name="__codelineno-8-62"></a>                            num_workers=get_dataloader_workers()),
<a id="__codelineno-8-63" name="__codelineno-8-63"></a>            data.DataLoader(mnist_test, batch_size, shuffle=False,
<a id="__codelineno-8-64" name="__codelineno-8-64"></a>                            num_workers=get_dataloader_workers()))
<a id="__codelineno-8-65" name="__codelineno-8-65"></a>
<a id="__codelineno-8-66" name="__codelineno-8-66"></a>train_iter, test_iter = load_data_fashion_mnist(32, resize=64)
<a id="__codelineno-8-67" name="__codelineno-8-67"></a>for X, y in train_iter:
<a id="__codelineno-8-68" name="__codelineno-8-68"></a>    print(X.shape, X.dtype, y.shape, y.dtype)
<a id="__codelineno-8-69" name="__codelineno-8-69"></a>    break
</code></pre></div></td></tr></table></div>
<h3 id="36-softmax"><span>3.6 softmax<span class="heti-spacing"> </span></span>回归的从零开始实现<a class="headerlink" href="#36-softmax" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1">  1</a></span>
<span class="normal"><a href="#__codelineno-9-2">  2</a></span>
<span class="normal"><a href="#__codelineno-9-3">  3</a></span>
<span class="normal"><a href="#__codelineno-9-4">  4</a></span>
<span class="normal"><a href="#__codelineno-9-5">  5</a></span>
<span class="normal"><a href="#__codelineno-9-6">  6</a></span>
<span class="normal"><a href="#__codelineno-9-7">  7</a></span>
<span class="normal"><a href="#__codelineno-9-8">  8</a></span>
<span class="normal"><a href="#__codelineno-9-9">  9</a></span>
<span class="normal"><a href="#__codelineno-9-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-9-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-9-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-9-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-9-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-9-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-9-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-9-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-9-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-9-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-9-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-9-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-9-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-9-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-9-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-9-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-9-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-9-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-9-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-9-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-9-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-9-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-9-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-9-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-9-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-9-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-9-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-9-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-9-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-9-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-9-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-9-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-9-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-9-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-9-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-9-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-9-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-9-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-9-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-9-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-9-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-9-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-9-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-9-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-9-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-9-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-9-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-9-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-9-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-9-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-9-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-9-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-9-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-9-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-9-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-9-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-9-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-9-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-9-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-9-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-9-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-9-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-9-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-9-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-9-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-9-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-9-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-9-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-9-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-9-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-9-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-9-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-9-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-9-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-9-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-9-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-9-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-9-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-9-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-9-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-9-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-9-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-9-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-9-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-9-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-9-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-9-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-9-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-9-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-9-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-9-100">100</a></span>
<span class="normal"><a href="#__codelineno-9-101">101</a></span>
<span class="normal"><a href="#__codelineno-9-102">102</a></span>
<span class="normal"><a href="#__codelineno-9-103">103</a></span>
<span class="normal"><a href="#__codelineno-9-104">104</a></span>
<span class="normal"><a href="#__codelineno-9-105">105</a></span>
<span class="normal"><a href="#__codelineno-9-106">106</a></span>
<span class="normal"><a href="#__codelineno-9-107">107</a></span>
<span class="normal"><a href="#__codelineno-9-108">108</a></span>
<span class="normal"><a href="#__codelineno-9-109">109</a></span>
<span class="normal"><a href="#__codelineno-9-110">110</a></span>
<span class="normal"><a href="#__codelineno-9-111">111</a></span>
<span class="normal"><a href="#__codelineno-9-112">112</a></span>
<span class="normal"><a href="#__codelineno-9-113">113</a></span>
<span class="normal"><a href="#__codelineno-9-114">114</a></span>
<span class="normal"><a href="#__codelineno-9-115">115</a></span>
<span class="normal"><a href="#__codelineno-9-116">116</a></span>
<span class="normal"><a href="#__codelineno-9-117">117</a></span>
<span class="normal"><a href="#__codelineno-9-118">118</a></span>
<span class="normal"><a href="#__codelineno-9-119">119</a></span>
<span class="normal"><a href="#__codelineno-9-120">120</a></span>
<span class="normal"><a href="#__codelineno-9-121">121</a></span>
<span class="normal"><a href="#__codelineno-9-122">122</a></span>
<span class="normal"><a href="#__codelineno-9-123">123</a></span>
<span class="normal"><a href="#__codelineno-9-124">124</a></span>
<span class="normal"><a href="#__codelineno-9-125">125</a></span>
<span class="normal"><a href="#__codelineno-9-126">126</a></span>
<span class="normal"><a href="#__codelineno-9-127">127</a></span>
<span class="normal"><a href="#__codelineno-9-128">128</a></span>
<span class="normal"><a href="#__codelineno-9-129">129</a></span>
<span class="normal"><a href="#__codelineno-9-130">130</a></span>
<span class="normal"><a href="#__codelineno-9-131">131</a></span>
<span class="normal"><a href="#__codelineno-9-132">132</a></span>
<span class="normal"><a href="#__codelineno-9-133">133</a></span>
<span class="normal"><a href="#__codelineno-9-134">134</a></span>
<span class="normal"><a href="#__codelineno-9-135">135</a></span>
<span class="normal"><a href="#__codelineno-9-136">136</a></span>
<span class="normal"><a href="#__codelineno-9-137">137</a></span>
<span class="normal"><a href="#__codelineno-9-138">138</a></span>
<span class="normal"><a href="#__codelineno-9-139">139</a></span>
<span class="normal"><a href="#__codelineno-9-140">140</a></span>
<span class="normal"><a href="#__codelineno-9-141">141</a></span>
<span class="normal"><a href="#__codelineno-9-142">142</a></span>
<span class="normal"><a href="#__codelineno-9-143">143</a></span>
<span class="normal"><a href="#__codelineno-9-144">144</a></span>
<span class="normal"><a href="#__codelineno-9-145">145</a></span>
<span class="normal"><a href="#__codelineno-9-146">146</a></span>
<span class="normal"><a href="#__codelineno-9-147">147</a></span>
<span class="normal"><a href="#__codelineno-9-148">148</a></span>
<span class="normal"><a href="#__codelineno-9-149">149</a></span>
<span class="normal"><a href="#__codelineno-9-150">150</a></span>
<span class="normal"><a href="#__codelineno-9-151">151</a></span>
<span class="normal"><a href="#__codelineno-9-152">152</a></span>
<span class="normal"><a href="#__codelineno-9-153">153</a></span>
<span class="normal"><a href="#__codelineno-9-154">154</a></span>
<span class="normal"><a href="#__codelineno-9-155">155</a></span>
<span class="normal"><a href="#__codelineno-9-156">156</a></span>
<span class="normal"><a href="#__codelineno-9-157">157</a></span>
<span class="normal"><a href="#__codelineno-9-158">158</a></span>
<span class="normal"><a href="#__codelineno-9-159">159</a></span>
<span class="normal"><a href="#__codelineno-9-160">160</a></span>
<span class="normal"><a href="#__codelineno-9-161">161</a></span>
<span class="normal"><a href="#__codelineno-9-162">162</a></span>
<span class="normal"><a href="#__codelineno-9-163">163</a></span>
<span class="normal"><a href="#__codelineno-9-164">164</a></span>
<span class="normal"><a href="#__codelineno-9-165">165</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a>import torch
<a id="__codelineno-9-2" name="__codelineno-9-2"></a>from IPython import display
<a id="__codelineno-9-3" name="__codelineno-9-3"></a>from d2l import torch as d2l
<a id="__codelineno-9-4" name="__codelineno-9-4"></a>
<a id="__codelineno-9-5" name="__codelineno-9-5"></a>batch_size = 256
<a id="__codelineno-9-6" name="__codelineno-9-6"></a>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
<a id="__codelineno-9-7" name="__codelineno-9-7"></a>
<a id="__codelineno-9-8" name="__codelineno-9-8"></a>num_inputs = 784
<a id="__codelineno-9-9" name="__codelineno-9-9"></a>num_outputs = 10
<a id="__codelineno-9-10" name="__codelineno-9-10"></a>
<a id="__codelineno-9-11" name="__codelineno-9-11"></a>W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
<a id="__codelineno-9-12" name="__codelineno-9-12"></a>b = torch.zeros(num_outputs, requires_grad=True) # 初始化模型参数
<a id="__codelineno-9-13" name="__codelineno-9-13"></a>
<a id="__codelineno-9-14" name="__codelineno-9-14"></a>X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
<a id="__codelineno-9-15" name="__codelineno-9-15"></a>X.sum(0, keepdim=True), X.sum(1, keepdim=True) 
<a id="__codelineno-9-16" name="__codelineno-9-16"></a>
<a id="__codelineno-9-17" name="__codelineno-9-17"></a>def softmax(X):
<a id="__codelineno-9-18" name="__codelineno-9-18"></a>    X_exp = torch.exp(X)
<a id="__codelineno-9-19" name="__codelineno-9-19"></a>    partition = X_exp.sum(1, keepdim=True)
<a id="__codelineno-9-20" name="__codelineno-9-20"></a>    return X_exp / partition  # 这里应用了广播机制
<a id="__codelineno-9-21" name="__codelineno-9-21"></a>
<a id="__codelineno-9-22" name="__codelineno-9-22"></a>X = torch.normal(0, 1, (2, 5))
<a id="__codelineno-9-23" name="__codelineno-9-23"></a>X_prob = softmax(X)
<a id="__codelineno-9-24" name="__codelineno-9-24"></a>X_prob, X_prob.sum(1) # 定义softmax操作
<a id="__codelineno-9-25" name="__codelineno-9-25"></a>
<a id="__codelineno-9-26" name="__codelineno-9-26"></a>def net(X):
<a id="__codelineno-9-27" name="__codelineno-9-27"></a>    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) # 定义模型
<a id="__codelineno-9-28" name="__codelineno-9-28"></a>
<a id="__codelineno-9-29" name="__codelineno-9-29"></a>y = torch.tensor([0, 2])
<a id="__codelineno-9-30" name="__codelineno-9-30"></a>y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])
<a id="__codelineno-9-31" name="__codelineno-9-31"></a>y_hat[[0, 1], y] 
<a id="__codelineno-9-32" name="__codelineno-9-32"></a>def cross_entropy(y_hat, y):
<a id="__codelineno-9-33" name="__codelineno-9-33"></a>    return - torch.log(y_hat[range(len(y_hat)), y])
<a id="__codelineno-9-34" name="__codelineno-9-34"></a>
<a id="__codelineno-9-35" name="__codelineno-9-35"></a>cross_entropy(y_hat, y) # 定义损失函数
<a id="__codelineno-9-36" name="__codelineno-9-36"></a>
<a id="__codelineno-9-37" name="__codelineno-9-37"></a>def accuracy(y_hat, y):  #@save
<a id="__codelineno-9-38" name="__codelineno-9-38"></a>    """计算预测正确的数量"""
<a id="__codelineno-9-39" name="__codelineno-9-39"></a>    if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1:
<a id="__codelineno-9-40" name="__codelineno-9-40"></a>        y_hat = y_hat.argmax(axis=1)
<a id="__codelineno-9-41" name="__codelineno-9-41"></a>    cmp = y_hat.type(y.dtype) == y
<a id="__codelineno-9-42" name="__codelineno-9-42"></a>    return float(cmp.type(y.dtype).sum())
<a id="__codelineno-9-43" name="__codelineno-9-43"></a>
<a id="__codelineno-9-44" name="__codelineno-9-44"></a>def evaluate_accuracy(net, data_iter):  #@save
<a id="__codelineno-9-45" name="__codelineno-9-45"></a>    """计算在指定数据集上模型的精度"""
<a id="__codelineno-9-46" name="__codelineno-9-46"></a>    if isinstance(net, torch.nn.Module):
<a id="__codelineno-9-47" name="__codelineno-9-47"></a>        net.eval()  # 将模型设置为评估模式
<a id="__codelineno-9-48" name="__codelineno-9-48"></a>    metric = Accumulator(2)  # 正确预测数、预测总数
<a id="__codelineno-9-49" name="__codelineno-9-49"></a>    with torch.no_grad():
<a id="__codelineno-9-50" name="__codelineno-9-50"></a>        for X, y in data_iter:
<a id="__codelineno-9-51" name="__codelineno-9-51"></a>            metric.add(accuracy(net(X), y), y.numel())
<a id="__codelineno-9-52" name="__codelineno-9-52"></a>    return metric[0] / metric[1]
<a id="__codelineno-9-53" name="__codelineno-9-53"></a>
<a id="__codelineno-9-54" name="__codelineno-9-54"></a>class Accumulator:  #@save
<a id="__codelineno-9-55" name="__codelineno-9-55"></a>    """在n个变量上累加"""
<a id="__codelineno-9-56" name="__codelineno-9-56"></a>    def __init__(self, n):
<a id="__codelineno-9-57" name="__codelineno-9-57"></a>        self.data = [0.0] * n
<a id="__codelineno-9-58" name="__codelineno-9-58"></a>
<a id="__codelineno-9-59" name="__codelineno-9-59"></a>    def add(self, *args):
<a id="__codelineno-9-60" name="__codelineno-9-60"></a>        self.data = [a + float(b) for a, b in zip(self.data, args)]
<a id="__codelineno-9-61" name="__codelineno-9-61"></a>
<a id="__codelineno-9-62" name="__codelineno-9-62"></a>    def reset(self):
<a id="__codelineno-9-63" name="__codelineno-9-63"></a>        self.data = [0.0] * len(self.data)
<a id="__codelineno-9-64" name="__codelineno-9-64"></a>
<a id="__codelineno-9-65" name="__codelineno-9-65"></a>    def __getitem__(self, idx):
<a id="__codelineno-9-66" name="__codelineno-9-66"></a>        return self.data[idx]
<a id="__codelineno-9-67" name="__codelineno-9-67"></a>
<a id="__codelineno-9-68" name="__codelineno-9-68"></a>evaluate_accuracy(net, test_iter) # 分类精度
<a id="__codelineno-9-69" name="__codelineno-9-69"></a>
<a id="__codelineno-9-70" name="__codelineno-9-70"></a>def train_epoch_ch3(net, train_iter, loss, updater):  #@save
<a id="__codelineno-9-71" name="__codelineno-9-71"></a>    """训练模型一个迭代周期（定义见第3章）"""
<a id="__codelineno-9-72" name="__codelineno-9-72"></a>    # 将模型设置为训练模式
<a id="__codelineno-9-73" name="__codelineno-9-73"></a>    if isinstance(net, torch.nn.Module):
<a id="__codelineno-9-74" name="__codelineno-9-74"></a>        net.train()
<a id="__codelineno-9-75" name="__codelineno-9-75"></a>    # 训练损失总和、训练准确度总和、样本数
<a id="__codelineno-9-76" name="__codelineno-9-76"></a>    metric = Accumulator(3)
<a id="__codelineno-9-77" name="__codelineno-9-77"></a>    for X, y in train_iter:
<a id="__codelineno-9-78" name="__codelineno-9-78"></a>        # 计算梯度并更新参数
<a id="__codelineno-9-79" name="__codelineno-9-79"></a>        y_hat = net(X)
<a id="__codelineno-9-80" name="__codelineno-9-80"></a>        l = loss(y_hat, y)
<a id="__codelineno-9-81" name="__codelineno-9-81"></a>        if isinstance(updater, torch.optim.Optimizer):
<a id="__codelineno-9-82" name="__codelineno-9-82"></a>            # 使用PyTorch内置的优化器和损失函数
<a id="__codelineno-9-83" name="__codelineno-9-83"></a>            updater.zero_grad()
<a id="__codelineno-9-84" name="__codelineno-9-84"></a>            l.mean().backward()
<a id="__codelineno-9-85" name="__codelineno-9-85"></a>            updater.step()
<a id="__codelineno-9-86" name="__codelineno-9-86"></a>        else:
<a id="__codelineno-9-87" name="__codelineno-9-87"></a>            # 使用定制的优化器和损失函数
<a id="__codelineno-9-88" name="__codelineno-9-88"></a>            l.sum().backward()
<a id="__codelineno-9-89" name="__codelineno-9-89"></a>            updater(X.shape[0])
<a id="__codelineno-9-90" name="__codelineno-9-90"></a>        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
<a id="__codelineno-9-91" name="__codelineno-9-91"></a>    # 返回训练损失和训练精度
<a id="__codelineno-9-92" name="__codelineno-9-92"></a>    return metric[0] / metric[2], metric[1] / metric[2]
<a id="__codelineno-9-93" name="__codelineno-9-93"></a>
<a id="__codelineno-9-94" name="__codelineno-9-94"></a>class Animator:  #@save
<a id="__codelineno-9-95" name="__codelineno-9-95"></a>    """在动画中绘制数据"""
<a id="__codelineno-9-96" name="__codelineno-9-96"></a>    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
<a id="__codelineno-9-97" name="__codelineno-9-97"></a>                 ylim=None, xscale='linear', yscale='linear',
<a id="__codelineno-9-98" name="__codelineno-9-98"></a>                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
<a id="__codelineno-9-99" name="__codelineno-9-99"></a>                 figsize=(3.5, 2.5)):
<a id="__codelineno-9-100" name="__codelineno-9-100"></a>        # 增量地绘制多条线
<a id="__codelineno-9-101" name="__codelineno-9-101"></a>        if legend is None:
<a id="__codelineno-9-102" name="__codelineno-9-102"></a>            legend = []
<a id="__codelineno-9-103" name="__codelineno-9-103"></a>        d2l.use_svg_display()
<a id="__codelineno-9-104" name="__codelineno-9-104"></a>        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
<a id="__codelineno-9-105" name="__codelineno-9-105"></a>        if nrows * ncols == 1:
<a id="__codelineno-9-106" name="__codelineno-9-106"></a>            self.axes = [self.axes, ]
<a id="__codelineno-9-107" name="__codelineno-9-107"></a>        # 使用lambda函数捕获参数
<a id="__codelineno-9-108" name="__codelineno-9-108"></a>        self.config_axes = lambda: d2l.set_axes(
<a id="__codelineno-9-109" name="__codelineno-9-109"></a>            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
<a id="__codelineno-9-110" name="__codelineno-9-110"></a>        self.X, self.Y, self.fmts = None, None, fmts
<a id="__codelineno-9-111" name="__codelineno-9-111"></a>
<a id="__codelineno-9-112" name="__codelineno-9-112"></a>    def add(self, x, y):
<a id="__codelineno-9-113" name="__codelineno-9-113"></a>        # 向图表中添加多个数据点
<a id="__codelineno-9-114" name="__codelineno-9-114"></a>        if not hasattr(y, "__len__"):
<a id="__codelineno-9-115" name="__codelineno-9-115"></a>            y = [y]
<a id="__codelineno-9-116" name="__codelineno-9-116"></a>        n = len(y)
<a id="__codelineno-9-117" name="__codelineno-9-117"></a>        if not hasattr(x, "__len__"):
<a id="__codelineno-9-118" name="__codelineno-9-118"></a>            x = [x] * n
<a id="__codelineno-9-119" name="__codelineno-9-119"></a>        if not self.X:
<a id="__codelineno-9-120" name="__codelineno-9-120"></a>            self.X = [[] for _ in range(n)]
<a id="__codelineno-9-121" name="__codelineno-9-121"></a>        if not self.Y:
<a id="__codelineno-9-122" name="__codelineno-9-122"></a>            self.Y = [[] for _ in range(n)]
<a id="__codelineno-9-123" name="__codelineno-9-123"></a>        for i, (a, b) in enumerate(zip(x, y)):
<a id="__codelineno-9-124" name="__codelineno-9-124"></a>            if a is not None and b is not None:
<a id="__codelineno-9-125" name="__codelineno-9-125"></a>                self.X[i].append(a)
<a id="__codelineno-9-126" name="__codelineno-9-126"></a>                self.Y[i].append(b)
<a id="__codelineno-9-127" name="__codelineno-9-127"></a>        self.axes[0].cla()
<a id="__codelineno-9-128" name="__codelineno-9-128"></a>        for x, y, fmt in zip(self.X, self.Y, self.fmts):
<a id="__codelineno-9-129" name="__codelineno-9-129"></a>            self.axes[0].plot(x, y, fmt)
<a id="__codelineno-9-130" name="__codelineno-9-130"></a>        self.config_axes()
<a id="__codelineno-9-131" name="__codelineno-9-131"></a>        display.display(self.fig)
<a id="__codelineno-9-132" name="__codelineno-9-132"></a>        display.clear_output(wait=True)
<a id="__codelineno-9-133" name="__codelineno-9-133"></a>
<a id="__codelineno-9-134" name="__codelineno-9-134"></a>def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save
<a id="__codelineno-9-135" name="__codelineno-9-135"></a>    """训练模型（定义见第3章）"""
<a id="__codelineno-9-136" name="__codelineno-9-136"></a>    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
<a id="__codelineno-9-137" name="__codelineno-9-137"></a>                        legend=['train loss', 'train acc', 'test acc'])
<a id="__codelineno-9-138" name="__codelineno-9-138"></a>    for epoch in range(num_epochs):
<a id="__codelineno-9-139" name="__codelineno-9-139"></a>        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
<a id="__codelineno-9-140" name="__codelineno-9-140"></a>        test_acc = evaluate_accuracy(net, test_iter)
<a id="__codelineno-9-141" name="__codelineno-9-141"></a>        animator.add(epoch + 1, train_metrics + (test_acc,))
<a id="__codelineno-9-142" name="__codelineno-9-142"></a>    train_loss, train_acc = train_metrics
<a id="__codelineno-9-143" name="__codelineno-9-143"></a>    assert train_loss &lt; 0.5, train_loss
<a id="__codelineno-9-144" name="__codelineno-9-144"></a>    assert train_acc &lt;= 1 and train_acc &gt; 0.7, train_acc
<a id="__codelineno-9-145" name="__codelineno-9-145"></a>    assert test_acc &lt;= 1 and test_acc &gt; 0.7, test_acc
<a id="__codelineno-9-146" name="__codelineno-9-146"></a>
<a id="__codelineno-9-147" name="__codelineno-9-147"></a>lr = 0.1
<a id="__codelineno-9-148" name="__codelineno-9-148"></a>
<a id="__codelineno-9-149" name="__codelineno-9-149"></a>def updater(batch_size):
<a id="__codelineno-9-150" name="__codelineno-9-150"></a>    return d2l.sgd([W, b], lr, batch_size)
<a id="__codelineno-9-151" name="__codelineno-9-151"></a>
<a id="__codelineno-9-152" name="__codelineno-9-152"></a>num_epochs = 10
<a id="__codelineno-9-153" name="__codelineno-9-153"></a>train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater) # 训练
<a id="__codelineno-9-154" name="__codelineno-9-154"></a>
<a id="__codelineno-9-155" name="__codelineno-9-155"></a>def predict_ch3(net, test_iter, n=6):  #@save
<a id="__codelineno-9-156" name="__codelineno-9-156"></a>    """预测标签（定义见第3章）"""
<a id="__codelineno-9-157" name="__codelineno-9-157"></a>    for X, y in test_iter:
<a id="__codelineno-9-158" name="__codelineno-9-158"></a>        break
<a id="__codelineno-9-159" name="__codelineno-9-159"></a>    trues = d2l.get_fashion_mnist_labels(y)
<a id="__codelineno-9-160" name="__codelineno-9-160"></a>    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))
<a id="__codelineno-9-161" name="__codelineno-9-161"></a>    titles = [true +'\n' + pred for true, pred in zip(trues, preds)]
<a id="__codelineno-9-162" name="__codelineno-9-162"></a>    d2l.show_images(
<a id="__codelineno-9-163" name="__codelineno-9-163"></a>        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])
<a id="__codelineno-9-164" name="__codelineno-9-164"></a>
<a id="__codelineno-9-165" name="__codelineno-9-165"></a>predict_ch3(net, test_iter) # 预测
</code></pre></div></td></tr></table></div>
<h3 id="37-softmax"><span>3.7 softmax<span class="heti-spacing"> </span></span>回归的简洁实现<a class="headerlink" href="#37-softmax" title="Permanent link"><span><span class="heti-spacing"> </span>¶</span></a></h3>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-10-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-10-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-10-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-10-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-10-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-10-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-10-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-10-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-10-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-10-10">10</a></span>
<span class="normal"><a href="#__codelineno-10-11">11</a></span>
<span class="normal"><a href="#__codelineno-10-12">12</a></span>
<span class="normal"><a href="#__codelineno-10-13">13</a></span>
<span class="normal"><a href="#__codelineno-10-14">14</a></span>
<span class="normal"><a href="#__codelineno-10-15">15</a></span>
<span class="normal"><a href="#__codelineno-10-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1"></a>import torch
<a id="__codelineno-10-2" name="__codelineno-10-2"></a>from torch import nn
<a id="__codelineno-10-3" name="__codelineno-10-3"></a>from d2l import torch as d2l
<a id="__codelineno-10-4" name="__codelineno-10-4"></a>
<a id="__codelineno-10-5" name="__codelineno-10-5"></a>batch_size = 256
<a id="__codelineno-10-6" name="__codelineno-10-6"></a>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
<a id="__codelineno-10-7" name="__codelineno-10-7"></a>
<a id="__codelineno-10-8" name="__codelineno-10-8"></a># PyTorch不会隐式地调整输入的形状。因此，
<a id="__codelineno-10-9" name="__codelineno-10-9"></a># 我们在线性层前定义了展平层（flatten），来调整网络输入的形状
<a id="__codelineno-10-10" name="__codelineno-10-10"></a>net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))
<a id="__codelineno-10-11" name="__codelineno-10-11"></a>
<a id="__codelineno-10-12" name="__codelineno-10-12"></a>def init_weights(m):
<a id="__codelineno-10-13" name="__codelineno-10-13"></a>    if type(m) == nn.Linear:
<a id="__codelineno-10-14" name="__codelineno-10-14"></a>        nn.init.normal_(m.weight, std=0.01)
<a id="__codelineno-10-15" name="__codelineno-10-15"></a>
<a id="__codelineno-10-16" name="__codelineno-10-16"></a>net.apply(init_weights); # 初始化模型参数
</code></pre></div></td></tr></table></div>
<div class="arithmatex">\[
\begin{split}\begin{aligned}
\hat y_j &amp; =  \frac{\exp(o_j - \max(o_k))\exp(\max(o_k))}{\sum_k \exp(o_k - \max(o_k))\exp(\max(o_k))} \\
&amp; = \frac{\exp(o_j - \max(o_k))}{\sum_k \exp(o_k - \max(o_k))}.
\end{aligned}\end{split}
\]</div>
<div class="arithmatex">\[
\begin{split}\begin{aligned}
\log{(\hat y_j)} &amp; = \log\left( \frac{\exp(o_j - \max(o_k))}{\sum_k \exp(o_k - \max(o_k))}\right) \\
&amp; = \log{(\exp(o_j - \max(o_k)))}-\log{\left( \sum_k \exp(o_k - \max(o_k)) \right)} \\
&amp; = o_j - \max(o_k) -\log{\left( \sum_k \exp(o_k - \max(o_k)) \right)}.
\end{aligned}\end{split}
\]</div>
<div class="highlight"><table class="highlighttable"><tr><th class="filename" colspan="2"><span class="filename">Text Only</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-11-1">1</a></span>
<span class="normal"><a href="#__codelineno-11-2">2</a></span>
<span class="normal"><a href="#__codelineno-11-3">3</a></span>
<span class="normal"><a href="#__codelineno-11-4">4</a></span>
<span class="normal"><a href="#__codelineno-11-5">5</a></span>
<span class="normal"><a href="#__codelineno-11-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1"></a>loss = nn.CrossEntropyLoss(reduction='none') # LogSumExp技巧
<a id="__codelineno-11-2" name="__codelineno-11-2"></a>
<a id="__codelineno-11-3" name="__codelineno-11-3"></a>trainer = torch.optim.SGD(net.parameters(), lr=0.1) # 优化算法
<a id="__codelineno-11-4" name="__codelineno-11-4"></a>
<a id="__codelineno-11-5" name="__codelineno-11-5"></a>num_epochs = 10
<a id="__codelineno-11-6" name="__codelineno-11-6"></a>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) # 训练
</code></pre></div></td></tr></table></div>
<!-- <div id="statistics" class="card" style="width: 27em; border-color: transparent; opacity: 0; font-size: 75%">
    <div style="padding-left: 1em;">
        页面总数：<span id="total-pages"></span><br>
        总字数：<span id="total-words"></span><br>
        代码块行数：<span id="code-lines"></span><br>
        网站运行时间：<span id="web-time"></span>
    </div>
</div>

<div class="mac-content-container"></div>
    <div class="mac-content-block">
      <span class="mac-content-label">本文总阅读量:</span>
      <span id="busuanzi_value_page_pv"></span>次
</div> -->
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/WncFht" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.code.annotate", "content.action.view", "navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top", "content.code.copy"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
<script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
<script src="../../js/katex.js"></script>
<script src="https://cdn.tonycrane.cc/utils/katex.min.js"></script>
<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>